{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7809a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import hanlp\n",
    "import pickle\n",
    "import collections\n",
    "import keras\n",
    "import pydot\n",
    "import pydotplus\n",
    "from pydotplus import graphviz\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5845aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_data(file_path,label_cols,text_fea_cols,categorical_fea_cols,numeric_fea_cols,):\n",
    "    df_raw = pd.read_csv(file_path, header=0, error_bad_lines=False, delimiter='\\t', engine='python')    \n",
    "    df_raw.fillna(value=\"\",inplace=True)    \n",
    "    df_no_user=df_raw.iloc[:,1:]\n",
    "    \n",
    "    '''for easy debug'''\n",
    "    #df_no_user=df_no_user.head(3000)\n",
    "\n",
    "    labels=df_no_user.iloc[:,label_cols]\n",
    "    text_fea=df_no_user.iloc[:,text_fea_cols]\n",
    "    categorical_fea=df_no_user.iloc[:,categorical_fea_cols]\n",
    "    numeric_fea=df_no_user.iloc[:,numeric_fea_cols]\n",
    "       \n",
    "    return df_no_user,labels,text_fea,categorical_fea,numeric_fea\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d801fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categorical_fea(df):\n",
    "    df_encode=df.apply(LabelEncoder().fit_transform)\n",
    "    return df_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b767ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_numeric_fea(df):\n",
    "    df.replace('',0,inplace=True)\n",
    "    x = df.values\n",
    "    '''Attention vs min_max_scale,使用min_max_scale会导致准确率大幅下降，因为min-max映射到[0-1],而standard不是'''\n",
    "    std_scaler = preprocessing.StandardScaler() \n",
    "    x_scaled = std_scaler.fit_transform(x)\n",
    "    return pd.DataFrame(x_scaled,columns = df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ffef5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stop_words(filename):\n",
    "    with open(filename,'r',encoding=\"utf-8\") as f:\n",
    "        stopwords_raw = f.readlines()\n",
    "    return set([stop.strip() for stop in stopwords_raw])\n",
    "    \n",
    "\n",
    "def remove_stop_words(text,stopwords):\n",
    "    text_without_stopwords = []\n",
    "    for tokens in text:\n",
    "        tokens_new=[]\n",
    "        for t in tokens:\n",
    "            if t not in stopwords:\n",
    "                tokens_new.append(t)\n",
    "        text_without_stopwords.append(tokens_new)\n",
    "    return text_without_stopwords\n",
    "\n",
    "def text_regex(text,\n",
    "               regex='[a-zA-Z0-9’!\"#$%&\\'()*（）：；＋－+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~\\s]+'):\n",
    "    text_re=[]\n",
    "    text_re=[re.sub(regex,\"\",t) for t in text]\n",
    "    return text_re\n",
    "\n",
    "def text_seg(text):   \n",
    "    \n",
    "    tok = hanlp.load(hanlp.pretrained.tok.COARSE_ELECTRA_SMALL_ZH)\n",
    "    text_seg=tok(text)\n",
    "    stopwords=load_stop_words(\"../config/stopwords.txt\")\n",
    "    #print(\"stopwords=\",stopwords)\n",
    "    text_seg=remove_stop_words(text_seg,stopwords)\n",
    "    return text_seg\n",
    "\n",
    "def get_tokenizer(path,text=None,num_words=5000): \n",
    "    \n",
    "    try:\n",
    "        with open(path, 'rb') as handle:\n",
    "            tokenizer = pickle.load(handle)\n",
    "    except:\n",
    "        tokenizer=Tokenizer(num_words=num_words,oov_token='<OOV>',char_level=False)\n",
    "        tokenizer.fit_on_texts(text)\n",
    "    \"\"\"\n",
    "    比如\n",
    "    num_words=1000，则说明，在输入的index值中，padding=0，oov=1，。。。。。max=999\n",
    "    \"\"\"\n",
    "    print(\"tokenizer.num_words =\",tokenizer.num_words)\n",
    "    print(\"tokenizer.word_counts =\",len(tokenizer.word_counts))\n",
    "    print(\"tokenizer.word_index =\",len(tokenizer.word_index))\n",
    "    return tokenizer\n",
    "\n",
    "def save_tokenizer(tokenizer,path):\n",
    "    with open(path, 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        \n",
    "def process_text_fea(df,num_words=5000,token_path=None,max_len=50,text_matrix=False,matrix_mode='tfidf'):\n",
    "    print(\"num_words=\",num_words)\n",
    "    if len(df.columns.values)!=1:\n",
    "        raise Exception(\"df should has only one text type columns!\")\n",
    "    text=df.values.reshape(df.shape[0]).tolist()\n",
    "    text=text_regex(text)\n",
    "    text=text_seg(text)\n",
    "    text_token=[]\n",
    "    for text_ent in text:\n",
    "        token_str=\"\"\n",
    "        for token in text_ent:\n",
    "            token_str+=token+\" \"\n",
    "        text_token.append(token_str.strip())\n",
    "    \n",
    "    tokenizer=get_tokenizer(path=token_path,text=text_token,num_words=num_words)\n",
    "    '''为了防止不同版本的tokenizer混淆，暂时先不需要保存'''\n",
    "    #save_tokenizer(tokenizer,token_path)\n",
    "    \n",
    "    if text_matrix:\n",
    "        text_sequence=tokenizer.texts_to_sequences(texts=text_token)\n",
    "        text_sequence=tokenizer.sequences_to_matrix(sequences=text_sequence,mode=matrix_mode)\n",
    "        print(type(text_sequence))\n",
    "        print(\"text_sequence.shape=\",text_sequence.shape)\n",
    "    else:\n",
    "        text_sequence=tokenizer.texts_to_sequences(texts=text_token)\n",
    "        text_sequence=pad_sequences(sequences=text_sequence,padding=\"post\",maxlen=max_len,truncating='pre')\n",
    "        print(type(text_sequence))\n",
    "        print(\"text_sequence.shape=\",text_sequence.shape)\n",
    "    \n",
    "    text_sequence=np.asarray(text_sequence).tolist()\n",
    "    \n",
    "    return pd.DataFrame({df.columns.values[0]:text_sequence}),tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ec90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_and_feature(train_data,test_data,cost_label_col,recharge_label_col,text_fea_cols,categorical_fea_cols,numeric_fea_cols):\n",
    "    \n",
    "    train_cost_label=train_data[:,cost_label_col]\n",
    "    train_recharge_label=train_data[:,recharge_label_col]\n",
    "    train_text_fea=train_data[:,text_fea_cols]\n",
    "    train_cate_fea=train_data[:,categorical_fea_cols] \n",
    "    train_numeric_fea=train_data[:,numeric_fea_cols]\n",
    "    \n",
    "    test_cost_label=test_data[:,cost_label_col]\n",
    "    test_recharge_label=test_data[:,recharge_label_col]\n",
    "    test_text_fea=test_data[:,text_fea_cols]\n",
    "    test_cate_fea=test_data[:,categorical_fea_cols]\n",
    "    test_numeric_fea=test_data[:,numeric_fea_cols]\n",
    "    \n",
    "    ##此处加上这个是为了解决：Failed to convert a NumPy array to a Tensor (Unsupported object type int).\n",
    "    train_cost_label=np.asarray(train_cost_label).astype('int32')\n",
    "    train_recharge_label=np.asarray(train_recharge_label).astype('int32')\n",
    "    train_cate_fea=np.asarray(train_cate_fea).astype('int32')\n",
    "    train_numeric_fea=np.asarray(train_numeric_fea).astype('float32') ##float not int !!\n",
    "    \n",
    "    '''\n",
    "    单独处理train_text_fea，因为里面的元素是list，没法直接用上述方式转成int32\n",
    "    '''\n",
    "    train_text_fea=np.reshape(train_text_fea,(train_text_fea.shape[0],))\n",
    "    train_text_fea_convert=[]\n",
    "    for item in train_text_fea:\n",
    "        train_text_fea_convert.append(np.asarray(item))\n",
    "    train_text_fea=np.asarray(train_text_fea_convert).astype('int32')\n",
    "           \n",
    "    test_cost_label=np.asarray(test_cost_label).astype('int32')\n",
    "    test_recharge_label=np.asarray(test_recharge_label).astype('int32')\n",
    "    test_cate_fea=np.asarray(test_cate_fea).astype('int32')\n",
    "    test_numeric_fea=np.asarray(test_numeric_fea).astype('float32') ##float not int !!\n",
    "    \n",
    "    '''\n",
    "    单独处理test_text_fea，因为里面的元素是list，没法直接用上述方式转成int32\n",
    "    '''\n",
    "    test_text_fea=np.reshape(test_text_fea,(test_text_fea.shape[0],))\n",
    "    test_text_fea_convert=[]\n",
    "    for item in test_text_fea:\n",
    "        test_text_fea_convert.append(np.asarray(item))\n",
    "    test_text_fea=np.asarray(test_text_fea_convert).astype('int32')\n",
    "    \n",
    "    return train_cost_label,train_recharge_label,train_text_fea,train_cate_fea,train_numeric_fea,test_cost_label,test_recharge_label,test_text_fea,test_cate_fea,test_numeric_fea\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e717bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(df,original=True,all_label_cols=None,label_col=None,label_values=None,label_counts=None,repeat_noise_ratio=0.95,sample_noise_ratio=0.95):\n",
    "    \n",
    "    print('-'*10+\"label counts in all data\"+'-'*10)   \n",
    "    for lc in all_label_cols:\n",
    "        print('label: ',lc)\n",
    "        print(df_data.iloc[:,lc].value_counts())\n",
    "          \n",
    "    \n",
    "    data=df.values  \n",
    "    train_data,test_data=train_test_split(data,test_size=0.1)   \n",
    "    \n",
    "    if original==False:\n",
    "        if len(label_values)!=len(label_counts):\n",
    "            raise ValueError(\"list label_values'size isn't equal to list label_counts!\")\n",
    "        if len(np.unique(train_data[:,label_col]))!=len(label_counts):\n",
    "            raise ValueError(\"df data dosen't has all label type!\")\n",
    "        \n",
    "        print('-'*10+\"label counts in train data BEFORE sample|repeat|noise\"+'-'*10) \n",
    "        for lc in all_label_cols:\n",
    "            print('label: ',lc)\n",
    "            print(collections.Counter(train_data[:,lc]))\n",
    "            \n",
    "        train_data_dict={}\n",
    "        for i in label_values:\n",
    "            lv=label_values[i]\n",
    "            lc=label_counts[i]\n",
    "            #td=train_data[np.in1d(train_data[:, label_col], lv)]\n",
    "            td=train_data[np.equal(train_data[:, label_col], lv)]\n",
    "            td_other=train_data[np.not_equal(train_data[:, label_col], lv)]\n",
    "            if td.shape[0]>=lc:\n",
    "                print(\"label value=\",lv,\" more than need! need=\",lc,\" exist=\",td.shape[0])\n",
    "                noise_counts=math.ceil(lc*(1-sample_noise_ratio))\n",
    "                noise_idxs=np.random.randint(td_other.shape[0],size=min(noise_counts,td_other.shape[0]))\n",
    "                noise_td=td_other[noise_idxs,:]\n",
    "                print(\"noise data counts=\",noise_td.shape[0])\n",
    "                noise_td[:,label_col]=lv\n",
    "                               \n",
    "                sample_counts=lc-noise_td.shape[0]\n",
    "                sample_idxs=np.random.randint(td.shape[0],size=sample_counts)\n",
    "                sample_td=td[sample_idxs,:]\n",
    "                print(\"sample data counts=\",sample_td.shape[0])\n",
    "               \n",
    "                merge_td=np.concatenate((sample_td,noise_td),axis=0)\n",
    "                train_data_dict[lv]=np.asarray(merge_td)\n",
    "            elif td.shape[0]<lc:\n",
    "                print(\"label value=\",lv,\" less than need! need=\",lc,\" exist=\",td.shape[0])\n",
    "                lack_counts=lc-td.shape[0]\n",
    "                print(\"lack_counts=\",lack_counts)\n",
    "                noise_counts=math.ceil(lack_counts*(1-repeat_noise_ratio))\n",
    "                noise_idxs=np.random.randint(td_other.shape[0],size=noise_counts)\n",
    "                noise_td=td_other[noise_idxs,:]\n",
    "                print(\"noise data counts=\",noise_td.shape[0])\n",
    "                noise_td[:,label_col]=lv\n",
    "                \n",
    "                repeat_counts=lc-noise_counts\n",
    "                repeat_times=math.ceil(repeat_counts/td.shape[0])\n",
    "                repeat_td=np.repeat(td,repeat_times+2,axis=0)\n",
    "                \n",
    "                sample_idxs=np.random.randint(repeat_td.shape[0],size=repeat_counts)\n",
    "                repeat_td=repeat_td[sample_idxs,:]\n",
    "                print(\"repeat data counts=\",repeat_td.shape[0])\n",
    "                \n",
    "                merge_td=np.concatenate((repeat_td,noise_td),axis=0)\n",
    "                train_data_dict[lv]=np.asarray(merge_td)\n",
    "                \n",
    "        train_data=np.concatenate(list(train_data_dict.values()),axis=0)\n",
    "        print('-'*10+\"label counts in train data AFTER sample|repeat|noise\"+'-'*10) \n",
    "        for lc in all_label_cols:\n",
    "            print('label: ',lc)\n",
    "            print(collections.Counter(train_data[:,lc]))\n",
    "    \n",
    "    print(\"train_data.shape=\",train_data.shape)\n",
    "    print('-'*10+\"splited data counts\"+'-'*10)   \n",
    "    print('train:',train_data.shape)\n",
    "    print('test:',test_data.shape)\n",
    "    \n",
    "    return train_data,test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2fbb4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pre_trained_embedding(embedd_file):\n",
    "    pre_trained_embed={}\n",
    "    with open(embedd_file,'rb') as handle:\n",
    "        next(handle)\n",
    "        for line in handle:\n",
    "            values = line.split()\n",
    "            word = values[0].decode('utf-8')\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            pre_trained_embed[word] = coefs\n",
    "    \n",
    "    words_size=len(pre_trained_embed)\n",
    "    embed_size=len(pre_trained_embed[list(pre_trained_embed.keys())[0]])\n",
    "    print(f\"there are {words_size} words,every word has {embed_size} dimension\")\n",
    "    return pre_trained_embed\n",
    "\n",
    "\n",
    "def init_embed_with_pre_trained(tokenizer,pre_trained_embed): \n",
    "    embed_size=len(pre_trained_embed[list(pre_trained_embed.keys())[0]])\n",
    "    \n",
    "    '''此处是voca_size好，还是num_words好，为了节约空间，还是使用num_words吧'''\n",
    "    \n",
    "    voca_size=len(tokenizer.word_index)+1\n",
    "    embedding_matrix = np.zeros((voca_size, embed_size))\n",
    "    \n",
    "    #embedding_matrix = np.zeros((tokenizer.num_words, embed_size))\n",
    "    \n",
    "    hits=0\n",
    "    miss=0\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        embedding_vector = pre_trained_embed.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            hits+=1\n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "        else:\n",
    "            miss+=1\n",
    "    print(\"hits=\",hits)\n",
    "    print(\"miss=\",miss)\n",
    "    return embedding_matrix\n",
    "\n",
    "def init_embed_with_pre_trained_2(tokenizer,pre_trained_embed): \n",
    "    embed_size=len(pre_trained_embed[list(pre_trained_embed.keys())[0]])\n",
    "    \n",
    "    '''此处是voca_size好，还是num_words好，为了节约空间，还是使用num_words吧'''\n",
    "    \n",
    "    #voca_size=len(tokenizer.word_index)+1\n",
    "    #embedding_matrix = np.zeros((voca_size, embed_size))\n",
    "    \n",
    "    embedding_matrix = np.zeros((tokenizer.num_words, embed_size))\n",
    "    \n",
    "    hits=0\n",
    "    miss=0\n",
    "    effect_hits=0\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        embedding_vector = pre_trained_embed.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            hits+=1\n",
    "            if idx<tokenizer.num_words:\n",
    "                effect_hits+=1\n",
    "                embedding_matrix[idx] = embedding_vector\n",
    "        else:\n",
    "            miss+=1\n",
    "    print(\"hits=\",hits)\n",
    "    print(\"miss=\",miss)\n",
    "    print(\"effect_hits=\",effect_hits)\n",
    "    return embedding_matrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df51f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_block_of_model(max_sequence_length,num_words,text_embed_size,lstm_size):\n",
    "    inputs=tf.keras.layers.Input(shape=(max_sequence_length,),dtype=tf.int32,name='text_inputs')\n",
    "    print(\"text embed's input size=\",num_words)\n",
    "    embed_outputs=tf.keras.layers.Embedding(input_dim=num_words, output_dim=text_embed_size, input_length=max_sequence_length,embeddings_initializer=tf.initializers.random_normal)(inputs)\n",
    "    #lstm_outputs=Bidirectional(LSTM(lstm_size,activation=\"relu\",dropout=0.2,return_sequences=True))(embed_outputs)\n",
    "    lstm_outputs=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size,activation=\"relu\",dropout=0.2,return_sequences=False))(embed_outputs)\n",
    "    '''add batchnorm,to normlize the output for the same scale with numeric'''\n",
    "    norm_outputs=tf.keras.layers.BatchNormalization()(lstm_outputs)\n",
    "    return inputs,norm_outputs\n",
    "\n",
    "def text_block_of_model_text_matrix(num_words=5000,dense_size=100):\n",
    "    print(\"num_words=\",num_words)\n",
    "    inputs=tf.keras.layers.Input(shape=(num_words,),dtype=tf.float32,name='text_inputs')\n",
    "    #print(inputs.shape)\n",
    "    norm_outputs_1=tf.keras.layers.BatchNormalization()(inputs)\n",
    "    dense_outputs=tf.keras.layers.Dense(dense_size, activation='sigmoid')(norm_outputs_1)\n",
    "    norm_outputs_2=tf.keras.layers.BatchNormalization()(dense_outputs)\n",
    "    return inputs,norm_outputs_2\n",
    "\n",
    "def text_block_of_model_pre_trained(max_sequence_length,lstm_size,embedding_matrix):\n",
    "    voca_size=embedding_matrix.shape[0] ##包括padding和oov，num_words,只是保证输入的index是【0，num_words-1】\n",
    "    text_embed_size=embedding_matrix.shape[1]\n",
    "    inputs=tf.keras.layers.Input(shape=(max_sequence_length,),dtype=tf.int32,name='text_inputs')\n",
    "    print(f\"voca_size={voca_size},text_embed_size={text_embed_size}\")\n",
    "    embed_outputs=tf.keras.layers.Embedding(input_dim=voca_size, output_dim=text_embed_size, input_length=max_sequence_length,embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),trainable=False)(inputs)\n",
    "    #lstm_outputs=Bidirectional(LSTM(lstm_size,activation=\"relu\",dropout=0.2,return_sequences=True))(embed_outputs)\n",
    "    lstm_outputs=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size,activation=\"relu\",dropout=0.2,return_sequences=False))(embed_outputs)\n",
    "    '''add batchnorm,to normlize the output for the same scale with numeric'''\n",
    "    norm_outputs=tf.keras.layers.BatchNormalization()(lstm_outputs)\n",
    "    return inputs,norm_outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed32afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cate_block_of_model(cate_num_sizes,cate_embed_sizes):\n",
    "    inputs=[]\n",
    "    outputs=[]\n",
    "    if len(cate_num_sizes)!=len(cate_embed_sizes):\n",
    "        raise ValueError(\"cate size!= embed size!\")\n",
    "    for i in range(len(cate_num_sizes)):\n",
    "        inpt = tf.keras.layers.Input(shape=(1,),dtype=tf.int32,name='cate_inputs_'+str(i))\n",
    "        inputs.append(inpt)\n",
    "        print(\"cate \"+str(i)+\" size:cate_num_sizes=\",str(cate_num_sizes[i])+\" \")\n",
    "        embed = tf.keras.layers.Embedding(cate_num_sizes[i],cate_embed_sizes[i], trainable=True,embeddings_initializer=tf.initializers.random_normal)(inpt)\n",
    "        embed_rehsaped =tf.keras.layers.Reshape(target_shape=(cate_embed_sizes[i],))(embed)\n",
    "        outputs.append(embed_rehsaped)  \n",
    "    concate_outputs=tf.keras.layers.concatenate(outputs)\n",
    "    '''add batchnorm,to normlize the output for the same scale with numeric'''\n",
    "    norm_outputs=tf.keras.layers.BatchNormalization()(concate_outputs)\n",
    "    return inputs,norm_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91774250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_block_of_model(input_size,dense_size):\n",
    "    inputs=tf.keras.layers.Input(shape=(input_size,),dtype=tf.float32,name='numeric_inputs')\n",
    "    dense_outputs=tf.keras.layers.Dense(dense_size, activation='relu')(inputs)\n",
    "    norm_outputs=tf.keras.layers.BatchNormalization()(dense_outputs)\n",
    "    return inputs,norm_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d787cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_task_learning_model(cate_num_sizes,cate_embed_sizes,\n",
    "                                     numeric_input_size=200,numeric_dense_size=50,\n",
    "                                     text_max_sequence_length=50,\n",
    "                                     text_num_words=5000,\n",
    "                                     text_embed_size=100,\n",
    "                                     text_dense_size=40,\n",
    "                                     text_lstm_size=20,\n",
    "                                     text_matrix=False,\n",
    "                                     is_pre_trained=False,\n",
    "                                     inited_embedd_matrix=None):\n",
    "    \n",
    "    cate_inputs,cate_outputs=cate_block_of_model(cate_num_sizes,cate_embed_sizes)\n",
    "    if text_matrix:\n",
    "        text_inputs,text_outputs=text_block_of_model_text_matrix(num_words=text_num_words,dense_size=text_dense_size)  \n",
    "    else:\n",
    "        if is_pre_trained:\n",
    "            text_inputs,text_outputs=text_block_of_model_pre_trained(max_sequence_length=text_max_sequence_length,lstm_size=text_lstm_size,embedding_matrix=inited_embedd_matrix)\n",
    "        else:\n",
    "            text_inputs,text_outputs=text_block_of_model(max_sequence_length=text_max_sequence_length,num_words=text_num_words,text_embed_size=text_embed_size,lstm_size=text_lstm_size)\n",
    "        \n",
    "    numeric_inputs,numeric_outputs=numeric_block_of_model(input_size=numeric_input_size,dense_size=numeric_dense_size)\n",
    "    \n",
    "    outputs=tf.keras.layers.concatenate([cate_outputs,text_outputs,numeric_outputs])\n",
    "    outputs=tf.keras.layers.BatchNormalization()(outputs)\n",
    "    outputs=tf.keras.layers.Dense(60, activation='relu')(outputs)\n",
    "    outputs=tf.keras.layers.BatchNormalization()(outputs)\n",
    "    \n",
    "    outputs_cost=tf.keras.layers.Dense(20, activation='relu')(outputs)\n",
    "    outputs_cost=tf.keras.layers.BatchNormalization()(outputs_cost)\n",
    "    outputs_cost=tf.keras.layers.Dense(3, activation='softmax',name='outputs_cost')(outputs_cost)\n",
    "    \n",
    "    outputs_recharge=tf.keras.layers.Dense(20, activation='relu')(outputs)\n",
    "    outputs_recharge=tf.keras.layers.BatchNormalization()(outputs_recharge)\n",
    "    outputs_recharge=tf.keras.layers.Dense(3, activation='softmax',name='outputs_recharge')(outputs_recharge)\n",
    "    \n",
    "    model = Model(inputs=cate_inputs+[text_inputs,numeric_inputs], outputs=[outputs_cost,outputs_recharge])\n",
    "    \n",
    "    #model.summary()\n",
    "    tf.keras.utils.plot_model(model, to_file=model_architecture_image,show_shapes=True,show_dtype=True,show_layer_activations=True)\n",
    "    \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4076b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_multitask_model(model, gamma):\n",
    "        \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'outputs_cost': 'sparse_categorical_crossentropy', \n",
    "                        'outputs_recharge': 'sparse_categorical_crossentropy'},\n",
    "                  loss_weights={'outputs_cost': gamma, \n",
    "                                'outputs_recharge': 1 - gamma}, \n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5805604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_batch(model):  \n",
    "    start = time.time()\n",
    "    history =model.fit(x={'cate_inputs_0': train_cate_fea[:,0],\n",
    "                                'cate_inputs_1': train_cate_fea[:,1],\n",
    "                                'cate_inputs_2': train_cate_fea[:,2],\n",
    "                                'text_inputs': train_text_fea,\n",
    "                                'numeric_inputs':train_numeric_fea},\n",
    "                             y={'outputs_cost': train_cost_label,\n",
    "                                'outputs_recharge': train_recharge_label},\n",
    "                             validation_split=0.1,\n",
    "                             epochs=train_epochs, batch_size=32, verbose=1)\n",
    "    print(f'Training time: {time.time() - start}\\n')\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9713fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multitask_accuracies(training_history):\n",
    "    \n",
    "    plt.plot(range(len(history.history['outputs_cost_accuracy'])), history.history['outputs_cost_accuracy'], c='r', label='Cost')\n",
    "    plt.plot(range(len(history.history['outputs_recharge_accuracy'])), history.history['outputs_recharge_accuracy'], c='b', label='Recharge')\n",
    "\n",
    "    plt.plot(range(len(history.history['val_outputs_cost_accuracy'])), history.history['val_outputs_cost_accuracy'], c='r',linestyle='dashed', marker='o', label='Val-Cost')\n",
    "    plt.plot(range(len(history.history['val_outputs_recharge_accuracy'])), history.history['val_outputs_recharge_accuracy'], c='b', linestyle='dashed', marker='o', label='Val-Recharge')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7803f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_score(y_true,y_pred_prob):\n",
    "    pred_label=np.asarray([np.argmax(v) for v in y_pred_prob])\n",
    "    print('accuracy: %.3f' % accuracy_score(y_true, pred_label))\n",
    "    print('ovr macro auc: %.3f' % roc_auc_score(y_true, y_pred_prob,multi_class='ovo',average='macro')) #注意这里是prob\n",
    "    print('ovo macro auc: %.3f' % roc_auc_score(y_true, y_pred_prob, multi_class='ovr',average='macro')) #注意这里是prob\n",
    "    print('ovr weighted auc: %.3f' % roc_auc_score(y_true, y_pred_prob,multi_class='ovo',average='weighted')) #注意这里是prob\n",
    "    print('ovo weighted auc: %.3f' % roc_auc_score(y_true, y_pred_prob, multi_class='ovr',average='weighted')) #注意这里是prob\n",
    "    print('micro precision: %.3f' % precision_score(y_true, pred_label,average='micro'))\n",
    "    print('macro precision: %.3f' % precision_score(y_true, pred_label,average='macro'))\n",
    "    print('weighted precision: %.3f' % precision_score(y_true, pred_label,average='weighted'))\n",
    "    print('micro recall: %.3f' % recall_score(y_true, pred_label,average='micro'))\n",
    "    print('macro recall: %.3f' % recall_score(y_true, pred_label,average='macro'))\n",
    "    print('weighted recall: %.3f' % recall_score(y_true, pred_label,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60831173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** Multi-Task-Model Begin Running ******************************************************\n",
      "\n",
      "\n",
      "---------------------------------------- load data begin ----------------------------------------\n",
      "df_no_user.shape= (1000000, 271)\n",
      "labels.shape= (1000000, 2)\n",
      "text_fea.shape= (1000000, 1)\n",
      "categorical_fea.shape= (1000000, 3)\n",
      "numeric_fea.shape= (1000000, 265)\n",
      "   c_label  r_label                                    problem_content  \\\n",
      "0        2        2  采购员客服发布招聘信息刷新优化#电话联系 设置采购 客服精品刷新 效果不好 建议客户多发帖#...   \n",
      "\n",
      "   main_belong_loc1  main_belong_cate2 main_city_hierarchy  free_money_avg_1d  \\\n",
      "0              7578               3112                  二线                0.0   \n",
      "\n",
      "   free_money_avg_3d  free_money_avg_7d  free_money_avg_14d  ...  \\\n",
      "0           0.002022           0.006067            0.013146  ...   \n",
      "\n",
      "   m_login_counts_60d  sum_senti_score_latest_3month  \\\n",
      "0                   0                       1.184329   \n",
      "\n",
      "   count_senti_score_latest_3mont  avg_score_latest_3month  \\\n",
      "0                               6                 0.197388   \n",
      "\n",
      "   sum_senti_score_latest_6month  count_senti_score_latest_6mont  \\\n",
      "0                       3.911437                              12   \n",
      "\n",
      "   avg_score_latest_6month  sum_senti_score_latest_1year  \\\n",
      "0                 0.325953                      6.237927   \n",
      "\n",
      "   count_senti_score_latest_1year  avg_score_latest_1year  \n",
      "0                              20                0.311896  \n",
      "\n",
      "[1 rows x 271 columns]\n",
      "---------------------------------------- load data end ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('*'*27+\" Multi-Task-Model Begin Running \"+'**'*27+\"\\n\\n\")\n",
    "\n",
    "print('-'*40+\" load data begin \"+'-'*40)\n",
    "label_cols=[0,1]\n",
    "cost_label_col=0\n",
    "recharge_label_col=1\n",
    "text_fea_cols=[2]\n",
    "categorical_fea_cols=[3,4,5]\n",
    "numeric_fea_cols=list(range(6,271))\n",
    "recharge_label_values=[0,1,2]\n",
    "\n",
    "'''--tuning params--'''\n",
    "recharge_label_counts=[20000,40000,600000]\n",
    "is_raw=True\n",
    "gamma_values=[0.5]\n",
    "is_pre_trained=True\n",
    "text_matrix=False\n",
    "train_epochs=15\n",
    "repeat_noise_ratio=1\n",
    "sample_noise_ratio=1\n",
    "num_words=4000\n",
    "token_path=\"../tokenizer/tokenizer_4.2.3.pickle\" #Attention,别跟别的模型乱了词表，所以此处要specific\n",
    "max_sequence_len=30\n",
    "data_file=\"../data/train_data_nlp_and_number_and_category_and_sentiments_feature_multi_label__extra_large.txt\"\n",
    "embedd_file=\"../pretrain_embedd/sgns.zhihu.word\"\n",
    "model_architecture_image='../model/model_4.2.3.png'\n",
    "'''--tuning params--'''\n",
    "\n",
    "numeric_input_size=len(numeric_fea_cols)\n",
    "\n",
    "df_no_user,labels,text_fea,categorical_fea,numeric_fea=process_raw_data(\n",
    "    file_path=data_file,\n",
    "    label_cols=label_cols,\n",
    "    text_fea_cols=text_fea_cols,\n",
    "    categorical_fea_cols=categorical_fea_cols,\n",
    "    numeric_fea_cols=numeric_fea_cols\n",
    "    )\n",
    "\n",
    "print(\"df_no_user.shape=\",df_no_user.shape)\n",
    "print(\"labels.shape=\",labels.shape)\n",
    "print(\"text_fea.shape=\",text_fea.shape)\n",
    "print(\"categorical_fea.shape=\",categorical_fea.shape)\n",
    "print(\"numeric_fea.shape=\",numeric_fea.shape)\n",
    "print(df_no_user.head(1))\n",
    "print('-'*40+\" load data end \"+'-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69c140d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- process feature begin ----------------------------------------\n",
      "num_words= 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.num_words = 4000\n",
      "tokenizer.word_counts = 39185\n",
      "tokenizer.word_index = 39186\n",
      "<class 'numpy.ndarray'>\n",
      "text_sequence.shape= (1000000, 30)\n",
      "(1000000, 271)\n",
      "   c_label  r_label                                    problem_content  \\\n",
      "0        2        2  [2343, 92, 79, 3, 29, 17, 147, 19, 5, 18, 1386...   \n",
      "\n",
      "   main_belong_loc1  main_belong_cate2  main_city_hierarchy  \\\n",
      "0               444                135                    2   \n",
      "\n",
      "   free_money_avg_1d  free_money_avg_3d  free_money_avg_7d  \\\n",
      "0           -0.14997          -0.221571          -0.296424   \n",
      "\n",
      "   free_money_avg_14d  ...  m_login_counts_60d  sum_senti_score_latest_3month  \\\n",
      "0           -0.380058  ...           -0.020562                       -0.40815   \n",
      "\n",
      "   count_senti_score_latest_3mont  avg_score_latest_3month  \\\n",
      "0                       -0.147302                -0.464747   \n",
      "\n",
      "   sum_senti_score_latest_6month  count_senti_score_latest_6mont  \\\n",
      "0                       0.150605                        0.093285   \n",
      "\n",
      "   avg_score_latest_6month  sum_senti_score_latest_1year  \\\n",
      "0                 0.078633                      0.180491   \n",
      "\n",
      "   count_senti_score_latest_1year  avg_score_latest_1year  \n",
      "0                        0.226309               -0.076606  \n",
      "\n",
      "[1 rows x 271 columns]\n",
      "----------label counts in all data----------\n",
      "label:  0\n",
      "2    678125\n",
      "1    196610\n",
      "0    125265\n",
      "Name: c_label, dtype: int64\n",
      "label:  1\n",
      "2    968061\n",
      "1     21319\n",
      "0     10620\n",
      "Name: r_label, dtype: int64\n",
      "train_data.shape= (900000, 271)\n",
      "----------splited data counts----------\n",
      "train: (900000, 271)\n",
      "test: (100000, 271)\n",
      "---------------------------------------- process feature end ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*40+\" process feature begin \"+'-'*40)\n",
    "\n",
    "df_text_token,tokenizer=process_text_fea(df=text_fea,num_words=num_words,token_path=token_path,max_len=max_sequence_len,text_matrix=text_matrix) \n",
    "df_categorical_fea_enc=process_categorical_fea(categorical_fea)\n",
    "df_numeric_fea_scale=process_numeric_fea(numeric_fea)\n",
    "\n",
    "df_data=pd.concat([labels,df_text_token,df_categorical_fea_enc,df_numeric_fea_scale],axis=1)\n",
    "print(df_data.shape)\n",
    "print(df_data.head(1))\n",
    "\n",
    "if is_raw:\n",
    "    train_data,test_data=split_train_test_data(df_data,all_label_cols=label_cols,original=True)\n",
    "else:\n",
    "    train_data,test_data=split_train_test_data(df_data,all_label_cols=label_cols,original=False,\n",
    "                                               label_col=recharge_label_col,label_values=recharge_label_values,label_counts=recharge_label_counts,\n",
    "                                               repeat_noise_ratio=repeat_noise_ratio,sample_noise_ratio=sample_noise_ratio)\n",
    "\n",
    "print('-'*40+\" process feature end \"+'-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d385c507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- process pretrained embedding begin ----------------------------------------\n",
      "there are 259869 words,every word has 300 dimension\n",
      "hits= 16363\n",
      "miss= 22823\n",
      "effect_hits= 3439\n",
      "inited_embedd_matrix.shape= (4000, 300)\n",
      "---------------------------------------- process pretrained embedding end ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*40+\" process pretrained embedding begin \"+'-'*40)\n",
    "pre_trained_embed=get_pre_trained_embedding(embedd_file=embedd_file)\n",
    "inited_embedd_matrix=init_embed_with_pre_trained_2(tokenizer=tokenizer,pre_trained_embed=pre_trained_embed)\n",
    "print(\"inited_embedd_matrix.shape=\",inited_embedd_matrix.shape)\n",
    "print('-'*40+\" process pretrained embedding end \"+'-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "946ce8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- process label and feature begin ----------------------------------------\n",
      "train_cost_label.shape= (900000,)\n",
      "train_recharge_label.shape= (900000,)\n",
      "train_text_fea.shape= (900000, 30)\n",
      "train_cate_fea.shape= (900000, 3)\n",
      "train_numeric_fea.shape= (900000, 265)\n",
      "test_cost_label.shape= (100000,)\n",
      "test_recharge_label.shape= (100000,)\n",
      "test_text_fea.shape= (100000, 30)\n",
      "test_cate_fea.shape= (100000, 3)\n",
      "test_numeric_fea.shape= (100000, 265)\n",
      "---------------------------------------- process label and feature end ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*40+\" process label and feature begin \"+'-'*40)\n",
    "train_cost_label,train_recharge_label,train_text_fea,train_cate_fea,train_numeric_fea,test_cost_label,test_recharge_label,test_text_fea,test_cate_fea,test_numeric_fea=get_label_and_feature(\n",
    "    train_data,test_data,\n",
    "    cost_label_col,recharge_label_col,\n",
    "    text_fea_cols,categorical_fea_cols,numeric_fea_cols)\n",
    "\n",
    "print(\"train_cost_label.shape=\",train_cost_label.shape)\n",
    "print(\"train_recharge_label.shape=\",train_recharge_label.shape)\n",
    "print(\"train_text_fea.shape=\",train_text_fea.shape)\n",
    "print(\"train_cate_fea.shape=\",train_cate_fea.shape)\n",
    "print(\"train_numeric_fea.shape=\",train_numeric_fea.shape)\n",
    "\n",
    "print(\"test_cost_label.shape=\",test_cost_label.shape)\n",
    "print(\"test_recharge_label.shape=\",test_recharge_label.shape)\n",
    "print(\"test_text_fea.shape=\",test_text_fea.shape)\n",
    "print(\"test_cate_fea.shape=\",test_cate_fea.shape)\n",
    "print(\"test_numeric_fea.shape=\",test_numeric_fea.shape)\n",
    "\n",
    "print('-'*40+\" process label and feature end \"+'-'*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f4925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- train model begin ----------------------------------------\n",
      "train model for gamma=0.5\n",
      "cate 0 size:cate_num_sizes= 666 \n",
      "cate 1 size:cate_num_sizes= 182 \n",
      "cate 2 size:cate_num_sizes= 9 \n",
      "voca_size=4000,text_embed_size=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 11:49:41.052106: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "25313/25313 [==============================] - 529s 21ms/step - loss: 0.3907 - outputs_cost_loss: 0.6461 - outputs_recharge_loss: 0.1354 - outputs_cost_accuracy: 0.7373 - outputs_recharge_accuracy: 0.9668 - val_loss: 0.3747 - val_outputs_cost_loss: 0.6228 - val_outputs_recharge_loss: 0.1266 - val_outputs_cost_accuracy: 0.7494 - val_outputs_recharge_accuracy: 0.9695\n",
      "Epoch 2/15\n",
      "12688/25313 [==============>...............] - ETA: 4:15 - loss: 0.3719 - outputs_cost_loss: 0.6221 - outputs_recharge_loss: 0.1218 - outputs_cost_accuracy: 0.7484 - outputs_recharge_accuracy: 0.9698"
     ]
    }
   ],
   "source": [
    "\n",
    "print('-'*40+\" train model begin \"+'-'*40)\n",
    "\n",
    "cate_num_sizes=[]\n",
    "cate_embed_sizes=[]\n",
    "for c in categorical_fea_cols:\n",
    "    cs=train_data[:,c].max()+1 #attention +1 begin because from zero!!!    \n",
    "    cate_num_sizes.append(cs)\n",
    "    cate_embed_sizes.append(math.ceil(cs/20)+2)\n",
    "\n",
    "trained_models=list()\n",
    "training_histories=list()\n",
    "predict_results=list()\n",
    "for i in range(len(gamma_values)):\n",
    "    print(f\"train model for gamma={gamma_values[i]}\")\n",
    "    \n",
    "    model=create_multi_task_learning_model(cate_num_sizes=cate_num_sizes,\n",
    "                                           cate_embed_sizes=cate_embed_sizes,\n",
    "                                           text_max_sequence_length=max_sequence_len,\n",
    "                                           text_num_words=num_words,\n",
    "                                           text_embed_size=100,\n",
    "                                           text_dense_size=40,\n",
    "                                           text_lstm_size=20,\n",
    "                                           numeric_input_size=numeric_input_size,\n",
    "                                           numeric_dense_size=50,\n",
    "                                           text_matrix=text_matrix,\n",
    "                                           is_pre_trained=is_pre_trained,\n",
    "                                           inited_embedd_matrix=inited_embedd_matrix)\n",
    "    compile_multitask_model(model,gamma_values[i])\n",
    "    history=fit_batch(model)\n",
    "\n",
    "    pred_result=model.predict(x={'cate_inputs_0': test_cate_fea[:,0],\n",
    "                                    'cate_inputs_1': test_cate_fea[:,1],\n",
    "                                    'cate_inputs_2': test_cate_fea[:,2],\n",
    "                                    'text_inputs': test_text_fea,\n",
    "                                    'numeric_inputs':test_numeric_fea}\n",
    "                                 ,verbose=1,use_multiprocessing=True)\n",
    "    trained_models.append(model)\n",
    "    training_histories.append(history)\n",
    "    predict_results.append(pred_result)\n",
    "    \n",
    "print('-'*40+\" train model end \"+'-'*40)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "604b0eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- plot and evaluate begin ----------------------------------------\n",
      "plot for gamma=0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABXf0lEQVR4nO3deVwU9f8H8Ney3Ah4cygC5oGIJyoCnmneJplpVqhpmuVFmpqpeVSSmuZNmV81yyvTbivxvsobNTHLE0WI8AARuZbP74/PbxdWlmMRGHRez8djHrv7mePznmGZee9nPjOjEUIIEBEREamIhdIBEBEREZU1JkBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUx1LpAMqj7Oxs3Lx5E46OjtBoNEqHQ0REREUghMC9e/fg7u4OC4uC23iYAJlw8+ZNeHh4KB0GERERFcP169dRs2bNAqdhAmSCo6MjALkBnZycFI6GiIiIiiI5ORkeHh6G43hBmACZoD/t5eTkxASIiIjoMVOU7ivsBE1ERESqwwSIiIiIVIcJEBEREakOEyAiIiJSHSZAREREpDpMgIiIiEh1mAARERGR6jABIiIiItVhAkRERESqwztBU5nR6YADB4C4OMDNDWjbFtBqlY6qbCm9DVi/uusn5f8GStdfHmJQun4DQXkkJSUJACIpKalEl5uVJcSePUJs2CBfs7JKdPHluv6tW4WoWVMIIGeoWVOWq4XS24D1q7t+Pe6H1P0dUDqG0q7fnOM3EyATSiMBetK/dIXVrdEY1w3IMo2m7LaB0jteJbcB61d3/bnj4H5Ivd8BpWMoi/qZAD2ikk6A1PCly09WVt4d3sMxeHiUfjKi5I5XqW2QlSVEaqoQd+4I4e5ecP01aggRFydEYqIQt2/LeZKShLh3T4iUFCF0upzl6nRyyM4u3+vP+o1xP6Tu74DSMZRV/eYcvzVCCKHAmbdyLTk5Gc7OzkhKSnrkp8HrdICXF3DjhunxGg1QsyZw5UrRz4EKAWRlyfdWVvI1KwuIjQUyMoDMzJzXtDTg+eeB//7Lf3mVKwMffQRkZ8t4PT3lOVmdTi7js8/k+6ws+ap/n50tp+3RQ77PzgYWLJDz6HTyc1wcsH9/4evUq5dclo2NXKdKlYBGjXL+PW7ckNvK2hqwtJSv+nXP/19Kjj96FFi0KP+6x4wBWrQoPEYh5Ho9vI0zM+U4L6+caU+fBu7ckeNiY4E9ewpf/lNPAXZ2Ods4OzsnPv36bNkC/P13znj9oP/87ruAhUXOtH/+WXi9RTFuHODkJP8Gv/0GHDmSM06jMR7efBOoWlWO27dPnuvPyCi8joAAuW65l5v7tWdPoHp1uW7R0cCJE/lPGxiYM+2pU8CxY4XX/8wz8rWgbebjA7i6yuUmJpqeVv+9q1NH9m9ISCja/0BwMFCtGnDvHnDhQs765F43jQZwcZHrBgAPHsh9x8PT6FWqBFSpImPavRtIT8+/fisrGQMg/7/j4nLW5eH/Kzs7wNExZ1+k37+Y+v+ztpbTX7mSs98yRaOR66X/nmk0Be+3bGzkuunX9+bNnDr1seRe9u3b+S9Lr0IFOXh45JRdu5Z/3FZWxtPeuJHzXc/9d8jMBJKTi1a/lZX8H/bwyFmHf/+Vf2tT66fRALVq5ZT/+y+Qmpp3Op2u4L+/nqVlTuzVq8v32dky/gcPjJeZu44KFXKmTU+X61wce/YAHToUb17AvOM3EyATSjIB2rsX6Nix8OkaNgTs7YHBg4FRo2TZpUtA+/amD7gAEBYGfPKJfH/9uvE/ARER0eNmwwZg4MDiz2/O8ZtXgZWyuLiiTXfunHx9OFmKjc1/nthY4OuvgcuX5S9R/S//0kpp9b8KLCxy3ltaAra2svXKwgK4fz/n15uFhfzVcf9+4ct2cJDLEkL+grCzkwmdfllnzsjET98qkluFCkCzZjnT/vFH0X7pFMbW1viXyO+/A0lJOZ8tLHLW28YGCArKGXfhApCSIsdnZgK3bhVe31NPAc7Ocnm5l12zZs72TE6WibBWmzM+93snp5z59b9a//0X+PHHwuvv2xeoUSPnO5SdnfOqb20DZP1ZWca/9PV/l+xsmchrtbL8wQMgJka2BBXmmWdkq0LuX865ubrK74VGI7dD7l/0D89Tq1bOL9KzZ4Fvvim8/pEjZYtJ7haVh5fv7Z3TunX3LnDxoul4NRrZIujiIlu1liwpvP633gLq15fLPX487/bVv/fxAerVy2nViIw0/TcTAmjcWLZu/vGHbMktzOjRQJs2sgXh88+N193CIudzkyZAt26yLD1drt/DLYH6aRs2lH/X2bMLr79nT+Cdd3L2YcuXy/e5l6ePw91dxpC7dVT/4zB3rBqNbFXbvLnw+nv3ltu3Xbucsl27cvZhuVvEALnf6tLFeNrc+wh9bHFxsuW0MD16yP9Ba2sZi34dDh+W+5Dc+1b9NtFq5XbQT3vqlGyd1E+jH65dA9atKzyGUaPk98vCQn53rK3l/DExslVbv3/JvZ/SaOR2s7WV7xMS5HbIvY86fVr+aC+Mm1vh05QUtgCZoEQL0KxZQPPmstncx0eeuvrnHzl/fLz8B4qNlS0916/Lg2tBrK3lztrJqWjN/z/+KFub8vty53dQKoz+FGBsrOnErDinAPWn9h48kMPDTcC7dsmDyIMH8sC7alXhy3ztNbnTs7OT/8S2tnLbtWqVM83t23Kb2Nnl7BSKojS2gTlYv7rrB4q+H3rU0w/ltX6l/wZK118eYiir+s06fj9ad6MnU0l2gtZ3/DLV+U8/VK4sxHvvCTFokBBt28oOqQX3bJGDu7sQwcFChIYKMWOGEGvXCrF/vxA3buR0Wi2s/rLofKfv/PhwDGXR+XHPnqJtyz17Si8GIZTdBqyf9Su9H1C6fiGU/xsoXX95iKEs6udVYI+otK4CKygJMjVUqCBE48ZChIQIMX68EEuXCvHzz0JER8urex61/rL+x3v4CgAPjyd/x5+bUtuA9bN+ff1P+sGvKDEo/TdQsv7yEENp18+rwB5RSZ4C09u2DXjjDXluNLfq1eXVTrVry1NWuV9zX+FQEvWPG2d8NZqHh7w6qm/fkqmjMErd/XPbNqBfP/k+97ddv22/+ebJ3wasn/UDyu8HlK4fUP5voHT95SGG0qyfV4E9otJIgADZL+XDD2X/ET8/+Q9vY1Niiy+U0l96JZWHHS9ReaD0fkDp+unJxgToEZVWAkTK4o6XiOjJxsvgiUzQakvnChMiInr8WCgdABEREVFZYwJEREREqsMEiIiIiFSHCRARERGpDhMgIiIiUh0mQERERKQ6TICIiIhIdZgAERERkeowASIiIiLVYQJEREREqsMEiIiIiFSHCRARERGpDhMgIiIiUh0mQERERKQ6TICIiIhIdZgAERERkeowASIiIiLVUTwBWrFiBby9vWFrawt/f38cOHCgwOmXL1+OBg0awM7ODvXr18e6deuMxq9duxYajSbPkJaWVpqrQURERI8RSyUr37x5M8LCwrBixQoEBwfjs88+Q/fu3REdHY1atWrlmT4iIgJTpkzB559/jpYtW+Lo0aMYPnw4KlWqhN69exumc3JywoULF4zmtbW1LfX1ISIioseDRgghlKo8ICAAzZs3R0REhKGsQYMGCAkJQXh4eJ7pg4KCEBwcjPnz5xvKwsLCcPz4cRw8eBCAbAEKCwvD3bt3ixxHeno60tPTDZ+Tk5Ph4eGBpKQkODk5FWPNiIiIqKwlJyfD2dm5SMdvxU6BZWRk4MSJE+jSpYtReZcuXXD48GGT86Snp+dpybGzs8PRo0eRmZlpKEtJSYGnpydq1qyJXr164dSpUwXGEh4eDmdnZ8Pg4eFRzLUiIiKix4FiCVBiYiJ0Oh1cXFyMyl1cXBAfH29ynq5du2LVqlU4ceIEhBA4fvw4Vq9ejczMTCQmJgIAfHx8sHbtWvzwww/YuHEjbG1tERwcjH/++SffWKZMmYKkpCTDcP369ZJbUSIiIip3FO0DBAAajcbosxAiT5ne9OnTER8fj9atW0MIARcXFwwZMgTz5s2DVqsFALRu3RqtW7c2zBMcHIzmzZtj6dKlWLJkicnl2tjYwMbGpoTWiIiIiMo7xVqAqlatCq1Wm6e1JyEhIU+rkJ6dnR1Wr16N1NRUXL16FTExMfDy8oKjoyOqVq1qch4LCwu0bNmywBYgIiIiUhfFEiBra2v4+/sjMjLSqDwyMhJBQUEFzmtlZYWaNWtCq9Vi06ZN6NWrFywsTK+KEAJRUVFwc3MrsdiJiIjo8aboKbDx48cjNDQULVq0QGBgIFauXImYmBiMHDkSgOybExsba7jXz99//42jR48iICAAd+7cwcKFC/Hnn3/iiy++MCxz1qxZaN26NerWrYvk5GQsWbIEUVFRWL58uSLrSEREROWPognQgAEDcOvWLcyePRtxcXHw8/PD9u3b4enpCQCIi4tDTEyMYXqdTocFCxbgwoULsLKyQseOHXH48GF4eXkZprl79y5GjBiB+Ph4ODs7o1mzZti/fz9atWpV1qtHRERE5ZSi9wEqr8y5jwARERGVD4/FfYCIiIiIlMIEiIiIiFSHCRARERGpDhMgIiIiUh0mQERERKQ6TICIiIhIdZgAERERkeowASIiIiLVYQJEREREqsMEiIiIiFSHCRARERGpDhMgIiIiUh0mQERERKQ6TICIiIhIdZgAERERkeowASIiIiLVYQJEREREqsMEiIiIiFSHCRARERGpDhMgIiIiUh0mQERERKQ6TICIiIhIdZgAERERkeowASIiIiLVYQJEREREqsMEiIiIiFSHCRARERGpDhMgIiIiUh0mQERERKQ6TICIiIhIdZgAERERkeowASIiIiLVYQJEREREqsMEiIiIiFSHCRARERGpDhMgIiIiUh0mQERERKQ6TICIiIhIdZgAERERkeowASIiIiLVYQJEREREqsMEiIiIiFSHCRARERGpDhMgIiIiUh0mQERERKQ6TICIiIhIdZgAERERkeowASIiIiLVYQJEREREqsMEiIiIiFSHCRARERGpDhMgIiIiUh0mQERERKQ6TICIiIhIdZgAERERkeowASIiIiLVYQJEREREqsMEiIiIiFSHCRARERGpDhMgIiIiUh0mQERERKQ6iidAK1asgLe3N2xtbeHv748DBw4UOP3y5cvRoEED2NnZoX79+li3bl2eabZu3QpfX1/Y2NjA19cX3377bWmFT0RERI8hRROgzZs3IywsDFOnTsWpU6fQtm1bdO/eHTExMSanj4iIwJQpUzBz5kycO3cOs2bNwqhRo/Djjz8apvn9998xYMAAhIaG4vTp0wgNDUX//v1x5MiRslotIiIiKuc0QgihVOUBAQFo3rw5IiIiDGUNGjRASEgIwsPD80wfFBSE4OBgzJ8/31AWFhaG48eP4+DBgwCAAQMGIDk5Gb/88othmm7duqFSpUrYuHFjkeJKTk6Gs7MzkpKS4OTkVNzVIyIiojJkzvFbsRagjIwMnDhxAl26dDEq79KlCw4fPmxynvT0dNja2hqV2dnZ4ejRo8jMzAQgW4AeXmbXrl3zXaZ+ucnJyUYDERERPbkUS4ASExOh0+ng4uJiVO7i4oL4+HiT83Tt2hWrVq3CiRMnIITA8ePHsXr1amRmZiIxMREAEB8fb9YyASA8PBzOzs6GwcPD4xHXjoiIiMozxTtBazQao89CiDxletOnT0f37t3RunVrWFlZoU+fPhgyZAgAQKvVFmuZADBlyhQkJSUZhuvXrxdzbYiIiOhxoFgCVLVqVWi12jwtMwkJCXlacPTs7OywevVqpKam4urVq4iJiYGXlxccHR1RtWpVAICrq6tZywQAGxsbODk5GQ1ERET05FIsAbK2toa/vz8iIyONyiMjIxEUFFTgvFZWVqhZsya0Wi02bdqEXr16wcJCrkpgYGCeZe7YsaPQZRIREZF6WCpZ+fjx4xEaGooWLVogMDAQK1euRExMDEaOHAlAnpqKjY013Ovn77//xtGjRxEQEIA7d+5g4cKF+PPPP/HFF18Yljlu3Di0a9cOc+fORZ8+ffD9999j586dhqvEiIiIiBRNgAYMGIBbt25h9uzZiIuLg5+fH7Zv3w5PT08AQFxcnNE9gXQ6HRYsWIALFy7AysoKHTt2xOHDh+Hl5WWYJigoCJs2bcK0adMwffp0PPXUU9i8eTMCAgLKevWIiIionFL0PkDlFe8DRERE9Ph5LO4DRERERKQUJkBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUhwkQERERqQ4TICIiIlIdJkBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKpjqXQAREREAKDT6ZCZmal0GFTOWVtbw8Li0dtvmAAREZGihBCIj4/H3bt3lQ6FHgMWFhbw9vaGtbX1Iy2HCRARESlKn/xUr14d9vb20Gg0SodE5VR2djZu3ryJuLg41KpV65G+K0yAiIhIMTqdzpD8VKlSRelw6DFQrVo13Lx5E1lZWbCysir2ctgJmoiIFKPv82Nvb69wJPS40J/60ul0j7QcJkBERKQ4nvaioiqp7woTICIiIlIdJkBERESkOkyAiIiIiik+Ph5jxoxB7dq1YWNjAw8PD/Tu3Ru7du165GWvXbsWFStWfPQgySReBUZERFQMV69eRXBwMCpWrIh58+ahcePGyMzMxG+//YZRo0bhr7/+UjpEKgBbgIiIiIrhzTffhEajwdGjR9GvXz/Uq1cPDRs2xPjx4/HHH38AAGJiYtCnTx9UqFABTk5O6N+/P/7991/DMk6fPo2OHTvC0dERTk5O8Pf3x/Hjx7F37168+uqrSEpKgkajgUajwcyZMxVa0ycTW4CIiKh8EQJITS37eu3tgSJeYXT79m38+uuv+PDDD+Hg4JBnfMWKFSGEQEhICBwcHLBv3z5kZWXhzTffxIABA7B3714AwMsvv4xmzZohIiICWq0WUVFRsLKyQlBQEBYtWoT33nsPFy5cAABUqFChxFaVmAAREVF5k5oKKHGwT0kBTCQzply8eBFCCPj4+OQ7zc6dO3HmzBlcuXIFHh4eAIAvv/wSDRs2xLFjx9CyZUvExMRg4sSJhuXUrVvXML+zszM0Gg1cXV0fYaUoPzwFRkREZCYhBICC70lz/vx5eHh4GJIfAPD19UXFihVx/vx5AMD48ePx2muvoXPnzvjoo49w6dKl0g2cDJgAERFR+WJvL1tjynow427UdevWhUajMSQypgghTCZIuctnzpyJc+fOoWfPnti9ezd8fX3x7bffmr/NyGw8BUZEROWLRlPkU1FKqVy5Mrp27Yrly5dj7NixefoB3b17F76+voiJicH169cNrUDR0dFISkpCgwYNDNPWq1cP9erVw1tvvYWBAwdizZo1eO6552Btbf3Ij3ug/LEFiIiIqBhWrFgBnU6HVq1aYevWrfjnn39w/vx5LFmyBIGBgejcuTMaN26Ml19+GSdPnsTRo0cxaNAgtG/fHi1atMCDBw8wevRo7N27F9euXcOhQ4dw7NgxQ3Lk5eWFlJQU7Nq1C4mJiUhVomP4E8zsBMjLywuzZ89GTExMacRDRET0WPD29sbJkyfRsWNHTJgwAX5+fnjmmWewa9cuREREQKPR4LvvvkOlSpXQrl07dO7cGbVr18bmzZsBAFqtFrdu3cKgQYNQr1499O/fH927d8esWbMAAEFBQRg5ciQGDBiAatWqYd68eUqu7hNHI/Q9uYpo6dKlWLt2reHeBcOGDcNzzz0HGxub0oqxzCUnJ8PZ2RlJSUlwcnJSOhwioidWWloarly5Am9vb9ja2iodDj0GCvrOmHP8NrsFaMyYMThx4gROnDgBX19fjB07Fm5ubhg9ejROnjxp7uKIiIiIylyx+wA1adIEixcvRmxsLGbMmIFVq1ahZcuWaNKkCVavXg0zG5aIiIiIykyxrwLLzMzEt99+izVr1iAyMhKtW7fGsGHDcPPmTUydOhU7d+7Ehg0bSjJWIiIiohJhdgJ08uRJrFmzBhs3boRWq0VoaCg++eQTo7thdunSBe3atSvRQImIiIhKitkJUMuWLfHMM88gIiICISEhsLKyyjONr68vXnzxxRIJkIiIiKikmZ0AXb58GZ6engVO4+DggDVr1hQ7KCIiIqLSZHYn6ISEBBw5ciRP+ZEjR3D8+PESCYqIiIioNJmdAI0aNQrXr1/PUx4bG4tRo0aVSFBEREREpcnsBCg6OhrNmzfPU96sWTNER0eXSFBEREREpcnsBMjGxgb//vtvnvK4uDhYWvLZqkRERCVh5syZaNq0qdJhPLHMToCeeeYZTJkyBUlJSYayu3fv4t1338UzzzxTosERERGVV0OGDIFGo4FGo4GlpSVq1aqFN954A3fu3FE6NCoCs5tsFixYgHbt2sHT0xPNmjUDAERFRcHFxQVffvlliQdIRERUXnXr1g1r1qxBVlYWoqOjMXToUNy9excbN25UOrR8ZWZmmryFjdqY3QJUo0YNnDlzBvPmzYOvry/8/f2xePFinD17Fh4eHqURIxERUblkY2MDV1dX1KxZE126dMGAAQOwY8cOw/g1a9agQYMGsLW1hY+PD1asWGE0/40bN/Diiy+icuXKcHBwQIsWLfJcaf3ll1/Cy8sLzs7OePHFF3Hv3j3DuF9//RVt2rRBxYoVUaVKFfTq1QuXLl0yjL969So0Gg2+/vprdOjQAba2tvjqq6+QlZWFsWPHGuabPHkyBg8ejJCQEMO8QgjMmzcPtWvXhp2dHZo0aYJvvvmmhLegcorVacfBwQEjRowo6ViIiIggBJCaWvb12tsDGk3x5798+TJ+/fVXQ+vK559/jhkzZmDZsmVo1qwZTp06heHDh8PBwQGDBw9GSkoK2rdvjxo1auCHH36Aq6srTp48iezsbMMyL126hO+++w4//fQT7ty5g/79++Ojjz7Chx9+CAC4f/8+xo8fj0aNGuH+/ft477338NxzzyEqKgoWFjltHJMnT8aCBQuwZs0a2NjYYO7cuVi/fr0hQVu8eDG+++47dOzY0TDPtGnTsG3bNkRERKBu3brYv38/XnnlFVSrVg3t27cv/oYqL0QxnTt3Tvzyyy/i+++/NxqeBElJSQKASEpKUjoUIqIn2oMHD0R0dLR48OCBoSwlRQiZBpXtkJJiXuyDBw8WWq1WODg4CFtbWwFAABALFy4UQgjh4eEhNmzYYDTP+++/LwIDA4UQQnz22WfC0dFR3Lp1y+TyZ8yYIezt7UVycrKhbOLEiSIgICDfmBISEgQAcfbsWSGEEFeuXBEAxKJFi4ymc3FxEfPnzzd8zsrKErVq1RJ9+vQRQgiRkpIibG1txeHDh43mGzZsmBg4cGBBm6XUmfrO6Jlz/C7WnaCfe+45nD17FhqNxvDUd83/p806na6kcjMiIqJyrWPHjoiIiEBqaipWrVqFv//+G2PGjMF///2H69evY9iwYRg+fLhh+qysLDg7OwOQ/WebNWuGypUr57t8Ly8vODo6Gj67ubkhISHB8PnSpUuYPn06/vjjDyQmJhpaj2JiYuDn52eYrkWLFob3SUlJ+Pfff9GqVStDmVarhb+/v2H+6OhopKWl5bm4KSMjw9D/93FndgI0btw4eHt7Y+fOnahduzaOHj2KW7duYcKECfj4449LI0YiIlIRe3sgJUWZes3l4OCAOnXqAACWLFmCjh07YtasWRg9ejQAeRosICDAaB6tVgsAsLOzK3T5D3dW1mg0RqfIevfuDQ8PD3z++edwd3dHdnY2/Pz8kJGRkSfOh2keOt+nb9AAYKjj559/Ro0aNYyms7GxKTTux4HZCdDvv/+O3bt3o1q1arCwsICFhQXatGmD8PBwjB07FqdOnSqNOImISCU0GsDE8fqxMGPGDHTv3h1vvPEGatSogcuXL+Pll182OW3jxo2xatUq3L59u8BWoPzcunUL58+fx2effYa2bdsCAA4ePFjofM7OznBxccHRo0cN8+l0Opw6dcpw3yFfX1/Y2NggJibmyejvY4LZCZBOp0OFChUAAFWrVsXNmzdRv359eHp64sKFCyUeIBER0eOiQ4cOaNiwIebMmYOZM2di7NixcHJyQvfu3ZGeno7jx4/jzp07GD9+PAYOHIg5c+YgJCQE4eHhcHNzw6lTp+Du7o7AwMBC66pUqRKqVKmClStXws3NDTExMXjnnXeKFOeYMWMQHh6OOnXqwMfHB0uXLsWdO3cMrUKOjo54++238dZbbyE7Oxtt2rRBcnIyDh8+jAoVKmDw4MGPtJ3KA7MTID8/P5w5cwa1a9dGQEAA5s2bB2tra6xcuRK1a9cujRiJiIgeG+PHj8err76KixcvYtWqVZg/fz4mTZoEBwcHNGrUCGFhYQAAa2tr7NixAxMmTECPHj2QlZUFX19fLF++vEj1WFhYYNOmTRg7diz8/PxQv359LFmyBB06dCh03smTJyM+Ph6DBg2CVqvFiBEj0LVrV8PpOQB4//33Ub16dYSHh+Py5cuoWLEimjdvjnfffbc4m6Xc0YjcJ/2K4LfffsP9+/fRt29fXL58Gb169cJff/2FKlWqYPPmzXj66adLK9Yyk5ycDGdnZyQlJcHJyUnpcIiInlhpaWm4cuUKvL29YWtrq3Q4qpWdnY0GDRqgf//+eP/995UOp0AFfWfMOX6b3QLUtWtXw/vatWsjOjoat2/fRqVKlfJ0qCIiIqLy59q1a9ixYwfat2+P9PR0LFu2DFeuXMFLL72kdGhlxqw7QWdlZcHS0hJ//vmnUXnlypWZ/BARET0mLCwssHbtWrRs2RLBwcE4e/Ysdu7ciQYNGigdWpkxqwXI0tISnp6evNcPERHRY8zDwwOHDh1SOgxFmf0ssGnTpmHKlCm4fft2acRDREREVOrM7gO0ZMkSXLx4Ee7u7vD09Mxzc6WTJ0+WWHBEREREpcHsBCj3k2KJiIiIHkdmJ0AzZswojTiIiIiIyozZfYBK2ooVKwzX8vv7++PAgQMFTr9+/Xo0adIE9vb2cHNzw6uvvopbt24Zxq9duxYajSbPkJaWVtqrQkRERI8JsxMgCwsLaLXafAdzbN68GWFhYZg6dSpOnTqFtm3bonv37oiJiTE5/cGDBzFo0CAMGzYM586dw5YtW3Ds2DG89tprRtM5OTkhLi7OaOANtoiIiEjP7FNg3377rdHnzMxMnDp1Cl988QVmzZpl1rIWLlyIYcOGGRKYRYsW4bfffkNERATCw8PzTP/HH3/Ay8sLY8eOBQB4e3vj9ddfx7x584ym02g0cHV1NSsWIiKistShQwc0bdoUixYtUjoUVTK7BahPnz5GQ79+/fDhhx9i3rx5+OGHH4q8nIyMDJw4cQJdunQxKu/SpQsOHz5scp6goCDcuHED27dvhxAC//77L7755hv07NnTaLqUlBR4enqiZs2a6NWrV6FPqE9PT0dycrLRQEREjxmdDti7F9i4Ub6W4j3revfujc6dO5sc9/vvv0Oj0ZTYVdGnTp3CCy+8ABcXF9ja2qJevXoYPnw4/v777xJZ/pAhQ1R5gVOJ9QEKCAjAzp07izx9YmIidDodXFxcjMpdXFwQHx9vcp6goCCsX78eAwYMgLW1NVxdXVGxYkUsXbrUMI2Pjw/Wrl2LH374ARs3boStrS2Cg4Pxzz//5BtLeHg4nJ2dDYOHh0eR14OIiMqBbdsALy+gY0fgpZfkq5eXLC8Fw4YNw+7du3Ht2rU841avXo2mTZuiefPmj1zPTz/9hNatWyM9PR3r16/H+fPn8eWXX8LZ2RnTp09/5OWrmigBqampYty4caJevXpFnic2NlYAEIcPHzYq/+CDD0T9+vVNznPu3Dnh5uYm5s2bJ06fPi1+/fVX0ahRIzF06NB869HpdKJJkyZizJgx+U6TlpYmkpKSDMP169cFAJGUlFTk9SEiIvM9ePBAREdHiwcPHhR/IVu3CqHRCAEYDxqNHLZuLbmA/19mZqZwcXERM2fONCq/f/++cHR0FDNnzhQvvviiqFGjhrCzsxN+fn5iw4YNRtO2b99ejBs3Lt867t+/L6pWrSpCQkJMjr9z547h/d69e0XLli2FtbW1cHV1FZMnTxaZmZmG8Vu2bBF+fn7C1tZWVK5cWXTq1EmkpKSIGTNmCABGw549e8zeHmWpoO9MUlJSkY/fZvcBevihp0II3Lt3D/b29vjqq6+KvJyqVatCq9Xmae1JSEjI0yqkFx4ejuDgYEycOBEA0LhxYzg4OKBt27b44IMP4ObmlmceCwsLtGzZssAWIBsbG9jY2BQ5diIiKgP37+c/TqsFbG3laa5x42TK8zAhAI1Gju/TR86T33IfuqlvYSwtLTFo0CCsXbsW7733nuG4uGXLFmRkZOC1117Dxo0bMXnyZDg5OeHnn39GaGgoateujYCAgCLV8dtvvyExMRGTJk0yOb5ixYoAgNjYWPTo0QNDhgzBunXr8Ndff2H48OGwtbXFzJkzERcXh4EDB2LevHl47rnncO/ePRw4cABCCLz99ts4f/48kpOTsWbNGgDy+Z5qYHYC9MknnxglQBYWFqhWrRoCAgJQqVKlIi/H2toa/v7+iIyMxHPPPWcoj4yMRJ8+fUzOk5qaCktL45D1V54JU1/+/y+PiopCo0aNihwbERGVAxUq5D+uRw/g55+BAweAGzfyn04IOf7AAaBDB1nm5QUkJuadzkxDhw7F/PnzsXfvXnTs2BGAPP3Vt29f1KhRA2+//bZh2jFjxuDXX3/Fli1bipwA6X+4+/j4FDjdihUr4OHhgWXLlkGj0cDHxwc3b97E5MmT8d577yEuLg5ZWVno27cvPD09AcDomGhnZ4f09HTVXTxkdgI0ZMiQEqt8/PjxCA0NRYsWLRAYGIiVK1ciJiYGI0eOBABMmTIFsbGxWLduHQDZ6Wz48OGIiIhA165dERcXh7CwMLRq1Qru7u4AgFmzZqF169aoW7cukpOTsWTJEkRFRWH58uUlFjcREZUTcXElO50ZfHx8EBQUhNWrV6Njx464dOkSDhw4gB07dkCn0+Gjjz7C5s2bERsbi/T0dKSnp+d5fJTenDlzMGfOHMPn6OjofH/YP+z8+fMIDAw0apwIDg5GSkoKbty4gSZNmqBTp05o1KgRunbtii5duqBfv35mNVo8icxOgNasWYMKFSrghRdeMCrfsmULUlNTMXjw4CIva8CAAbh16xZmz56NuLg4+Pn5Yfv27YYMNS4uzuieQEOGDMG9e/ewbNkyTJgwARUrVsTTTz+NuXPnGqa5e/cuRowYgfj4eDg7O6NZs2bYv38/WrVqZe6qEhGRklJS8h+nP51louuDSbmnu3q12CE9bNiwYRg9ejSWL1+ONWvWwNPTE506dcL8+fPxySefYNGiRWjUqBEcHBwQFhaGjIwMk8sZOXIk+vfvb/js7u6OevXqAQD++usvBAYG5huDEMIo+dGXAfK2MFqtFpGRkTh8+DB27NiBpUuXYurUqThy5Ai8vb0fdRM8vsztfFSvXj2xe/fuPOV79+41qxN0eWZOJyoiIiq+R+4EnZUlRM2apjtB6ztCe3jI6UrBvXv3RIUKFURERISoWbOmmDVrlhBCiF69ehldoKPT6US9evVEnz59DGWFdYJOSUkpUifod999V9SvX19kZ2cbxi1fvlw4OjoKnU6XZ76srCxRo0YNsWDBAiGEEMOHDxe9evUq6iorrqQ6QZt9Gfy1a9dMZoyenp753sGZiIioVGi1wOLF8v1DrSCGz4sW5bQYlbAKFSpgwIABePfdd3Hz5k1DN5E6deoYWl3Onz+P119/Pd9bvOTHwcEBq1atws8//4xnn30WO3fuxNWrV3H8+HFMmjTJ0F3kzTffxPXr1zFmzBj89ddf+P777zFjxgyMHz8eFhYWOHLkCObMmYPjx48jJiYG27Ztw3///YcGDRoAALy8vHDmzBlcuHABiYmJyMzMLNFtVF6ZnQBVr14dZ86cyVN++vRpVKlSpUSCIiIiKrK+fYFvvgFq1DAur1lTlvftW6rVDxs2DHfu3EHnzp1Rq1YtAMD06dPRvHlzdO3aFR06dICrq2uxbjbYp08fHD58GFZWVnjppZfg4+ODgQMHIikpCR988AEAoEaNGti+fTuOHj2KJk2aYOTIkRg2bBimTZsGQD4eav/+/ejRowfq1auHadOmYcGCBejevTsAYPjw4ahfvz5atGiBatWq4dChQyWzYco5jRDmdX2fNGkSvv76a6xZswbt2rUDAOzbtw9Dhw5Fv3798PHHH5dKoGUpOTkZzs7OSEpKgpOTk9LhEBE9sdLS0nDlyhXDQ7EfiU4nr/aKi5N9ftq2LbWWH1JOQd8Zc47fZneC/uCDD3Dt2jV06tTJcEl6dnY2Bg0aZNSDnYiIqExptTmXuhMVwuwEyNraGps3b8YHH3yAqKgo2NnZoVGjRoYrt4iIiIjKO7MTIL26deuibt26JRkLERERUZkwuxN0v3798NFHH+Upnz9/fp57AxERERGVR2YnQPv27UPPnj3zlHfr1g379+8vkaCIiIiISpPZCVBKSgqsra3zlFtZWSE5OblEgiIiIiIqTWYnQH5+fti8eXOe8k2bNsHX17dEgiIiIiIqTWZ3gp4+fTqef/55XLp0CU8//TQAYNeuXdiwYQO++eabEg+QiIiIqKSZnQA9++yz+O677zBnzhx88803sLOzQ5MmTbB7927eNJCIiIgeC2afAgOAnj174tChQ7h//z4uXryIvn37IiwsDP7+/iUdHxERUZHodMDevcDGjfJVp1M6ooJ16NABYWFhSodRbuIoa8VKgABg9+7deOWVV+Du7o5ly5ahR48eOH78eEnGRkREVCTbtgFeXkDHjsBLL8lXLy9ZXhp69+6Nzp07mxz3+++/Q6PR4OTJk49cj5eXFzQaDTQaDezs7ODj44P58+fDzKdYkQlmnQK7ceMG1q5di9WrV+P+/fvo378/MjMzsXXrVnaAJiIiRWzbBvTrBzycE8TGyvLSeB7qsGHD0LdvX1y7di3PkxBWr16Npk2bonnz5iVS1+zZszF8+HCkpaVh586deOONN+Dk5ITXX3+9RJZfGnQ6HTQaDSwsit3OUuqKHFmPHj3g6+uL6OhoLF26FDdv3sTSpUtLMzYiIlKx+/fzH9LS5DQ6HTBuXN7kB8gpGzfO+HSYqeWZq1evXqhevTrWrl1rVJ6amorNmzcjJCQEAwcORM2aNWFvb49GjRph48aN5lcEwNHREa6urvDy8sJrr72Gxo0bY8eOHYbxGRkZmDRpEmrUqAEHBwcEBARg7969Rss4dOgQ2rdvD3t7e1SqVAldu3bFnTt3DOOzs7MxadIkVK5cGa6urpg5c6bR/AsXLkSjRo3g4OAADw8PvPnmm0hJSTGMX7t2LSpWrIiffvoJvr6+sLGxwbVr1xAXF4eePXvCzs4O3t7e2LBhA7y8vLBo0SLDvElJSRgxYgSqV68OJycnPP300zh9+nSxtpU5ipwA7dixA6+99hpmzZqFnj17Qssn7BIRUSmqUCH/4fnn5TQHDgA3buS/DCHk+AMHcsq8vPIuz1yWlpYYNGgQ1q5da3Q6asuWLcjIyMBrr70Gf39//PTTT/jzzz8xYsQIhIaG4siRI+ZXZlgXgb179+L8+fOwsrIylL/66qs4dOgQNm3ahDNnzuCFF15At27d8M8//wAAoqKi0KlTJzRs2BC///47Dh48iN69e0OXKyv84osv4ODggCNHjmDevHmYPXs2IiMjDeMtLCywZMkS/Pnnn/jiiy+we/duTJo0ySi+1NRUhIeHY9WqVTh37hyqV6+OQYMG4ebNm9i7dy+2bt2KlStXIiEhwWidevbsifj4eGzfvh0nTpxA8+bN0alTJ9y+fbvY26pIRBEdPnxYvPbaa8LJyUm0atVKLF26VCQkJAhLS0tx7ty5oi7msZCUlCQAiKSkJKVDISJ6oj148EBER0eLBw8e5Bkn0xfTQ48ecpoNGwqeTj9s2JCz3KpV844vjvPnzwsAYvfu3Yaydu3aiYEDB5qcvkePHmLChAmGz+3btxfjxo0rsA5PT09hbW0tHBwchJWVlQAgbG1txaFDh4QQQly8eFFoNBoRGxtrNF+nTp3ElClThBBCDBw4UAQHB+dbR/v27UWbNm2Mylq2bCkmT56c7zxff/21qFKliuHzmjVrBAARFRVlKNNvn2PHjhnK/vnnHwFAfPLJJ0IIIXbt2iWcnJxEWlqa0fKfeuop8dlnn5msu6DvjDnH7yL3AQoMDERgYCAWL16MTZs2YfXq1Rg/fjyys7MRGRkJDw8PODo6lkqSRkRE6pPrDEse+pMQbm5FW1bu6a5eLXZIRnx8fBAUFITVq1ejY8eOuHTpEg4cOIAdO3ZAp9Pho48+wubNmxEbG4v09HSkp6fDwcHB5LLmzJmDOXPmGD5HR0ejVq1aAICJEydiyJAh+O+//zB16lQ8/fTTCAoKAgCcPHkSQgjUq1fPaHnp6emoUqUKANkCVNizOhs3bmz02c3NzailZs+ePZgzZw6io6ORnJyMrKwspKWl4f79+4Z1sra2NlrOhQsXYGlpadQXqk6dOqhUqZLh84kTJ5CSkmKIVe/Bgwe4dOlSgTE/KrPvA2Rvb4+hQ4di6NChuHDhAv73v//ho48+wjvvvINnnnkGP/zwQ2nESUREKpNPrmCkbVugZk3Z4dlUPyCNRo5v29a85RbVsGHDMHr0aCxfvhxr1qyBp6cnOnXqhPnz5+OTTz7BokWLDH1nwsLCkJGRYXI5I0eORP/+/Q2f3d3dDe+rVq2KOnXqoE6dOti6dSvq1KmD1q1bo3PnzsjOzoZWq8WJEyfydE2p8P/n9uzs7Apdj9yn1ABAo9EgOzsbAHDt2jX06NEDI0eOxPvvv4/KlSvj4MGDGDZsGDIzMw3z2NnZQaPRGD6LfK5Uy12enZ0NNze3PH2WAKBixYqFxv0oHql7dv369TFv3jzcuHGj2J27iIiIikurBRYvlu9zHXuNPi9alNNiVNL69+8PrVaLDRs24IsvvsCrr74KjUaDAwcOoE+fPnjllVfQpEkT1K5d29Anx5TKlSsbkpw6derA0tJ0+0SlSpUwZswYvP322xBCoFmzZtDpdEhISDCav06dOnB1dQUgW3d27dpV7HU8fvw4srKysGDBArRu3Rr16tXDzZs3C53Px8cHWVlZOHXqlKHs4sWLuHv3ruFz8+bNER8fD0tLyzzxV61atdgxF0WJXJ+m1WoREhLC1h8iIipzffvKS91r1DAur1mzdC6Bz61ChQoYMGAA3n33Xdy8eRNDhgwBIE/1REZG4vDhwzh//jxef/11xMfHl0ido0aNwoULF7B161bUq1cPL7/8MgYNGoRt27bhypUrOHbsGObOnYvt27cDAKZMmYJjx47hzTffxJkzZ/DXX38hIiICiYmJRarvqaeeQlZWFpYuXYrLly/jyy+/xKefflrofD4+PujcuTNGjBiBo0eP4tSpUxgxYoRRS1Hnzp0RGBiIkJAQ/Pbbb7h69SoOHz6MadOmlfq9BcvvBfpERERF1Lev7NuzZw+wYYN8vXKldJMfvWHDhuHOnTvo3Lmzod/O9OnT0bx5c3Tt2hUdOnSAq6srQkJCSqS+atWqITQ0FDNnzkR2djbWrFmDQYMGYcKECahfvz6effZZHDlyBB4eHgCAevXqYceOHTh9+jRatWqFwMBAfP/99/m2Mj2sadOmWLhwIebOnQs/Pz+sX78e4eHhRZp33bp1cHFxQbt27fDcc89h+PDhcHR0hK2tLQB5qm379u1o164dhg4dinr16uHFF1/E1atX4eLiUrwNVEQakd9JOhVLTk6Gs7MzkpKS+HwzIqJSlJaWhitXrsDb29twUKQn140bN+Dh4YGdO3eiU6dOxVpGQd8Zc47fZneCJiIiIiqK3bt3IyUlBY0aNUJcXBwmTZoELy8vtGvXTunQmAARERFR6cjMzMS7776Ly5cvw9HREUFBQVi/fn2eq86UwASIiIiISkXXrl3RtWtXpcMwiZ2giYiISHWYABERkeJ4PQ4VVUl9V5gAERGRYvR9QVJTUxWOhB4X+rtpP+pD2dkHiIiIFKPValGxYkXDc6fs7e2NHqdAlFt2djb+++8/2NvbF/k+RvlhAkRERIrSP7Ih98M3ifJjYWGBWrVqPXKizASIiIgUpdFo4ObmhurVqxs9XJPIFGtra1hYPHoPHiZARERULmi12kfu10FUVOwETURERKrDBIiIiIhUhwkQERERqQ4TICIiIlIdJkBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUhwkQERERqQ4TICIiIlIdJkBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUhwkQERERqQ4TICIiIlIdJkBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUhwkQERERqY7iCdCKFSvg7e0NW1tb+Pv748CBAwVOv379ejRp0gT29vZwc3PDq6++ilu3bhlNs3XrVvj6+sLGxga+vr749ttvS3MViIiI6DGjaAK0efNmhIWFYerUqTh16hTatm2L7t27IyYmxuT0Bw8exKBBgzBs2DCcO3cOW7ZswbFjx/Daa68Zpvn9998xYMAAhIaG4vTp0wgNDUX//v1x5MiRslotIiIiKuc0QgihVOUBAQFo3rw5IiIiDGUNGjRASEgIwsPD80z/8ccfIyIiApcuXTKULV26FPPmzcP169cBAAMGDEBycjJ++eUXwzTdunVDpUqVsHHjxiLFlZycDGdnZyQlJcHJyam4q0dERERlyJzjt2ItQBkZGThx4gS6dOliVN6lSxccPnzY5DxBQUG4ceMGtm/fDiEE/v33X3zzzTfo2bOnYZrff/89zzK7du2a7zIBID09HcnJyUYDERERPbkUS4ASExOh0+ng4uJiVO7i4oL4+HiT8wQFBWH9+vUYMGAArK2t4erqiooVK2Lp0qWGaeLj481aJgCEh4fD2dnZMHh4eDzCmhEREVF5p3gnaI1GY/RZCJGnTC86Ohpjx47Fe++9hxMnTuDXX3/FlStXMHLkyGIvEwCmTJmCpKQkw6A/nUZERERPJkulKq5atSq0Wm2elpmEhIQ8LTh64eHhCA4OxsSJEwEAjRs3hoODA9q2bYsPPvgAbm5ucHV1NWuZAGBjYwMbG5tHXCMiIiJ6XCjWAmRtbQ1/f39ERkYalUdGRiIoKMjkPKmpqbCwMA5Zq9UCkK08ABAYGJhnmTt27Mh3mURERKQ+irUAAcD48eMRGhqKFi1aIDAwECtXrkRMTIzhlNaUKVMQGxuLdevWAQB69+6N4cOHIyIiAl27dkVcXBzCwsLQqlUruLu7AwDGjRuHdu3aYe7cuejTpw++//577Ny5EwcPHlRsPYmIiKh8UTQBGjBgAG7duoXZs2cjLi4Ofn5+2L59Ozw9PQEAcXFxRvcEGjJkCO7du4dly5ZhwoQJqFixIp5++mnMnTvXME1QUBA2bdqEadOmYfr06XjqqaewefNmBAQElPn6ERERUfmk6H2AyiveB4iIiOjx81jcB4iIiIhIKUyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUhwkQERERqQ4TICIiIlIdJkBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUhwkQERERqQ4TICIiIlIdJkBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUhwkQERERqQ4TICIiIlIdJkBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUhwkQERERqQ4TICIiIlIdJkBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUhwkQERERqQ4TICIiIlIdJkBERESkOkyAiIiISHUslQ6AiIhINXQ64MABIC4OcHMD2rYFtFqloypb5WQbMAEiIqKyo/TBT8n6t20Dxo0DbtzIKatZE1i8GOjbt2xiUFo52gYaIYQo0xofA8nJyXB2dkZSUhKcnJyUDoeISorSB1+1U/rgp2T927YB/foBDx9yNRr5+s03xY8hOxtISwMePDD9+nBZaioQHQ0kJQFOTkCdOoCFRU4sJfFqquzECWD58rzxl8Q2+H/mHL+ZAJnABIjoCaT0wbe8UCoJLM0EoCTq37AB6N1bbh+dDsjKynmfe8iv/N49mVjcvy9fU1Nzkg2tVn7Pbt3KPz57e+D55wFLSxmTqcQlv+QmI6P0tltZ0Wjk/+OVK4/0fWQC9IiYANETS+kWELUefPWU3v4lmQTqWx30B+Pcw8NlqanAhAmyxSE/trbAwIHyb5SeDvzzj3yfnS0H/XshAGtrwMFBbs/MTJlY6KfTDzqdfAXk3zkxMe/f/0mk1cpkytYWsLMzfk1JAc6dy3/e4GCgRg35Xr+t9Ns9I0Nu64wMmQTqP2s0gIdHzvRnzshkMDNTDllZ8rWo237PHqBDh2KvPhOgR8QEiEqNmvsfKFW/Tgd4eRnXm1sJ/fIsVGmsvxDyQJSWJpMGfULy8Of0dGDfPuDjj/NfVpcu8jtZUCKTuzw9vXgxPymsrIBq1eR3RqsFrl+X3zWNRp5O0g/68ffuFW2Zrq7AG2/kJC7vvgvcuWN6+tq15d9VP23r1sCff8r3lSoBlSvL10qV5P/Atm35/x8AMnFq2xaoXh1Yty6n3McHuHDB9Dy1agHXruV8DggAjh4tfF3zs2GDTISLyZzjNztBE5WV8tj/IDZWlit1+qG49Qshf83eupUz3L4tX7t0AerWldPt2gWMGVPwTl8IefBatUru9J2dZb8IR0egQgU5ODgArVoBTz0lf9HeuwfExwM2NnIQIu8v3tyf//jDdN+HGzfkaY/u3eUv78KSGFPjSsqOHSW3LL1q1QA/P/m3OX268OlfeAHw95fb7euvc1roAOPvjp+f/L5YWsry6dONpxEi532LFkCjRsDkyYXX/9xz8gCsT1oWL5Yx2NvnHapWBXx9c+ZNTZWJiIWJu8vs3Qt07Fh4/Tt2AO3bG693gwbAf//JJOjhwc1N7kP09C1s+kT15s2ccR4eBf8f6Nfht99kUpObs7N8dXCQ752dgYoV5au7u/G0U6fK/w/9eP3r2bNAz56FbwM3t8KnKSFsATKBLUBU4pQ8BaN0C0hR6nd3B7ZskTv6hAQ5JCbmJDY9ewKenvKgv2ePTCZ0OtPLe/ppOW1amlynP/4oWpyWljJZeZzlbn1wdJQHaVtb2S/l0qXC5x8xQh6AZs3Kf5rnnwcWLJCtDELI1opq1eRQtWrOUK2a/F65uBQ9AXjE0x/5Urp+/f9AbKzpU0El9T+YnQ0kJ8vk6PZt42QpKgqIiCh8GSNGyL5QvXrllN27J79HVlbFj62MtgFPgT0iJkBPKKVOPxU3AdHpjK/MuH4duHpVtnzcvy9fc78fM0Y2XQPAl18Ca9bIcf/+a9xEnR99c33u5nsLC+D773MOHuvWARMn5r3CA5A7tYED5S/Ne/fkL/59+2TScv++OVusfLKwkH1PLP+/4TwlJf9pPT3ldrCykjv8v/8ufPlDh8pf2EuX5j/N8OHA6NHyYHTtmmztys/bbwPz58v3ixcDYWGFx7BhAxASArz3nnEikzuxqVjRdCtHQcoqASiv9QM5P4IA4xjKqh+a0kkgUCbbgKfAqHxSU/+XjIycUzM7dxbtFEydOvKzPrFJS5MdQfXlK1YAH32U/3L69s1JgG7ckDsyc+g7jz5s0CBZfu9e4f0YFi0yr878aLUy0bC0lElHpUrywGtrK8v0LRwVKsgyGxv5mnvQl1lby6Tt9m3TdWk0spVi//6c5VtZ5Qz6OEwd9DMy5C/upCTjoXFj2T8DkEnIpEmFr3PnzvI02/XrOXVbWxu/79pVLhsAqlSRy85v2vr1c5bdoEHRtrubm2zZ0SdOJUV/OqlfP7m9TR38Fi0qvf2B0vUD8v/zm29M74cWLSr90+Bt28q6CksC27YtvRiU3gYPYQuQCWwBKgXlsf+LOb86EhLkgUmf1OhPz+iHzz6TB2RAtsQsW1YysW/aJA9K9+7JU0S//mp8QNavgxDyIK7vn3LnjnxNSyu9K19M9YuoVk0emB0dZWypqTKWH38sfHnbtwPPPJPTwlKSlPz1XR5+eZeHFhDA9H7Aw6PsDn5K1w8o/0NQyVYovVLcBjwF9oiYAJWw8tz/BZAtC6+/Lg/UuROcgwdzOv+9/jqwcmX+y7h4UXaQzcyUl/suXSoTlAoV5AE9v9aH3GxsZIuCEv+SDg7y3L+zc07LiqOj6aFCBZnsFPU0iNoPvuVp/Z/wg99jUb/SykMSWIqYAD0iJkAlqCj9X2rUAE6dkn1F9DcQa9IkZ5qDB+UlmPpxD99sbOVK2eQPADNnAlu35oxLSpJXQxTH/v3yaqDbt4FPP5VXaOhPqeh3mNnZOffCSEoquF+IOTQa4yTk4YSksM8Pl/36K9C/v1y2Egc/tR98y8v6P+EHPyqiJzgJZAL0iJ7YBKgsvvRCAHfvyssvY2OB3buBuXPNX05GRs4VBy+/LDtn5ufWLXm/C6Dwlpr8ODvL+vRJWH5XGBVVxYoyJv19OFJTgUOH8p9+/nygT5/itbAUldIHP6XrV1p5Wf8n+OBHxAToET2RCVBJ9MF58EDuNGNjZYKTmAiMGpUzftAg+Uu2uC0uVlY5fUkuXMjpU7NggexHkbuviYODbI3R6eSVMPqk6/RpeXWM/jLQuLjit8pYWeUkMbmTmcLKnJ1NH1DKwwFQ6YOf0vUrTe3rT1TKmAA9oicuASqsD87XX8tboMfGys6+PXrkTPPuu7ID682bpvuxpKXJviuATIC+/FK+r1RJntqytQWOHy88xshIeRUMIE8rJSbKOk0N+gTs339Lpr9MpUqyE3PVqsaJjL298WXeJYEHQCKiUsME6BE9UQlQUToBPyx3UjNkCPDFFznj7OxkYuPuLl9XrJCnewB5jxqdTo6zszOuP78OoIA85dO5s0wKbt6Ur0W9IZ1WK28d7+6ed9DHefIk8Oqrcnol+18QEVGp4n2A1EwIeQooKkp2LC7sHjR6+rvxurvLzrz6+8mMHSv74OgTCmfn/FtFvLxyYrh+XZ7G+usveRv6gmJISQG++y5vPNWrm05scg/6Z/EUpFEjeTqtnNx7goiIlMcWIBMeyxagL74A1q6Vic/du+bP/9VXMtExR2qqvMOtPtHRv/79d9Hu/GtrCwQGAkFBeRMbF5dHu+26KTz9RET0RHusWoBWrFiB+fPnIy4uDg0bNsSiRYvQNp87UQ4ZMgRf5D4d8/98fX1x7tw5AMDatWvxqv50Ry4PHjyAra1tyQZvrkc5ACcnA2fO5LTsREXJy731rS43bsiOwoBMHBo2BJo1k52Fi3JTvho1TJcLIU9fPZzkXLgAxMTkvzxLS3kH4/r15ZOE69eXn2/flomTEgmIVlt6N5ojIqLHiqIJ0ObNmxEWFoYVK1YgODgYn332Gbp3747o6GjUevhptAAWL16Mj3I9CiArKwtNmjTBCy+8YDSdk5MTLly4YFSmePJTnKuw9uyRfWyiouSN9h528mROAtSnj0ximjWTt73X3xdHp5Onlwq7CVuLFvIKKlOtOQVdRVWlSk6Ck/vV27vkW3CIiIhKiKKnwAICAtC8eXNE5HpCbYMGDRASEoLw8PBC5//uu+/Qt29fXLlyBZ6engBkC1BYWBjuFuc00P8r8VNghV2FNW6cTFhOnQKmTQPatZPlmzcDL76YM33NmkDTpjLJadpUtqBUq1b0+gHTSVC1avKqq/y+ClqtvMvxw4lO/fryyikiIqJy4LE4BZaRkYETJ07gnXfeMSrv0qULDh8+XKRl/O9//0Pnzp0NyY9eSkoKPD09odPp0LRpU7z//vto1qxZvstJT09Henq64XNycrIZa1IInU4mOKaSC31Z7gdIPvNMTgIUHCxvkNe0qRyKm2z07StvJDhypOzg/LD//pOvlSsbJzf697Vr57QoERERPQEUS4ASExOh0+ng4uJiVO7i4oL4+PhC54+Li8Mvv/yCDQ/dIdjHxwdr165Fo0aNkJycjMWLFyM4OBinT59G3bp1TS4rPDwcs2bNKv7KFOTAgaJdhfXss0DPnsYPTaxZE3j77UerXwjZkvTOOznJT9WqQN26sgOyr29OssPWHCIiUgnFO0FrHrqkWgiRp8yUtWvXomLFiggJCTEqb926NVq3bm34HBwcjObNm2Pp0qVYsmSJyWVNmTIF48ePN3xOTk6Gh4eHGWtRgLi4ok334ovAwIElU6fe4cPA+PHAkSPyc82aQHg48NJLJf+YBSIioseIYglQ1apVodVq87T2JCQk5GkVepgQAqtXr0ZoaCisCzk1Y2FhgZYtW+Kff/7JdxobGxvY6G/8V9Lc3Ep2uqK4fFm2+GzZIj9XqCA/v/WWvLsxERGRyinWDGBtbQ1/f39ERkYalUdGRiIoKKjAefft24eLFy9i2LBhhdYjhEBUVBTcSjLBMEfbtrLlJb9WLY1GPg8qn0v/zXL3LjBxorwKbMsW2cozfDjwzz/A1KlMfoiIiP6foqfAxo8fj9DQULRo0QKBgYFYuXIlYmJiMHLkSADy1FRsbCzWrVtnNN///vc/BAQEwM/PL88yZ82ahdatW6Nu3bpITk7GkiVLEBUVheXLl5fJOuWh1cpL3fv1k8mOqUcxLFr0aPfDycyUz7KaOVM+GR2QnakXLJB3QSYiIiIjiiZAAwYMwK1btzB79mzExcXBz88P27dvN1zVFRcXh5iHbraXlJSErVu3YvHixSaXeffuXYwYMQLx8fFwdnZGs2bNsH//frRq1arU1ydfffvK502V9KMYhAB++km2+ujve+TrC3z8MdCtW8k/yJOIiOgJwUdhmFBqj8IoyUcxnDoFTJggb5YIyHv5vP8+MGyYvAszERGRyjwW9wFSpZJ4FENsrLxZ4hdfyBYgGxt5pdc77wCPy3PLiIiIFMYE6HFx/768KeL8+fJZWoC8nH3OHOChG0ESERFRwZgAlXc6HbBunbyKS39PoeBgYOFCQMl+TURERI8xJkDl2e7dsp9PVJT8XLs2MHcu8Pzz7OBMRET0CJgAlUd//QVMmgT8+KP87OwMTJ8OjB4t+/wQERHRI2ECVJ4kJsp7+Xz6qTz1ZWkJvPkm8N57QJUqSkdHRET0xGACVB6kpwNLlgAffpjzwNI+fYB584B69ZSNjYiI6AnEBEhJQshHVrzzDnDliixr1kzewTn3U+GJiIioRDEBUsoff8j79/z+u/zs7i4vaQ8N5ZPaiYiIShkToLJ29SowZQqwaZP8bG8PTJ4sr/ZycFA0NCIiIrVgAlSWtm2TNy9MT5eXsb/6qnx8hbu70pERERGpChOgshQYKK/satNGPrC0aVOlIyIiIlIlJkBlyc0NOH1a3tCQNzIkIiJSDBOgsvbUU0pHQEREpHq83IiIiIhUhwkQERERqQ4TICIiIlIdJkBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUhwkQERERqQ4TICIiIlIdJkBERESkOkyAiIiISHX4NHgThBAAgOTkZIUjISIioqLSH7f1x/GCMAEy4d69ewAADw8PhSMhIiIic927dw/Ozs4FTqMRRUmTVCY7Oxs3b96Eo6MjNBpNiS47OTkZHh4euH79OpycnEp02Y8Dta8/wG3A9Vf3+gPcBmpff6D0toEQAvfu3YO7uzssLAru5cMWIBMsLCxQs2bNUq3DyclJtV98gOsPcBtw/dW9/gC3gdrXHyidbVBYy48eO0ETERGR6jABIiIiItVhAlTGbGxsMGPGDNjY2CgdiiLUvv4AtwHXX93rD3AbqH39gfKxDdgJmoiIiFSHLUBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECVIZWrFgBb29v2Nrawt/fHwcOHFA6pDITHh6Oli1bwtHREdWrV0dISAguXLigdFiKCQ8Ph0ajQVhYmNKhlKnY2Fi88sorqFKlCuzt7dG0aVOcOHFC6bDKRFZWFqZNmwZvb2/Y2dmhdu3amD17NrKzs5UOrdTs378fvXv3hru7OzQaDb777juj8UIIzJw5E+7u7rCzs0OHDh1w7tw5ZYItBQWtf2ZmJiZPnoxGjRrBwcEB7u7uGDRoEG7evKlcwCWssL9/bq+//jo0Gg0WLVpUZvExASojmzdvRlhYGKZOnYpTp06hbdu26N69O2JiYpQOrUzs27cPo0aNwh9//IHIyEhkZWWhS5cuuH//vtKhlbljx45h5cqVaNy4sdKhlKk7d+4gODgYVlZW+OWXXxAdHY0FCxagYsWKSodWJubOnYtPP/0Uy5Ytw/nz5zFv3jzMnz8fS5cuVTq0UnP//n00adIEy5YtMzl+3rx5WLhwIZYtW4Zjx47B1dUVzzzzjOF5jI+7gtY/NTUVJ0+exPTp03Hy5Els27YNf//9N5599lkFIi0dhf399b777jscOXIE7u7uZRTZ/xNUJlq1aiVGjhxpVObj4yPeeecdhSJSVkJCggAg9u3bp3QoZerevXuibt26IjIyUrRv316MGzdO6ZDKzOTJk0WbNm2UDkMxPXv2FEOHDjUq69u3r3jllVcUiqhsARDffvut4XN2drZwdXUVH330kaEsLS1NODs7i08//VSBCEvXw+tvytGjRwUAce3atbIJqgzlt/43btwQNWrUEH/++afw9PQUn3zySZnFxBagMpCRkYETJ06gS5cuRuVdunTB4cOHFYpKWUlJSQCAypUrKxxJ2Ro1ahR69uyJzp07Kx1Kmfvhhx/QokULvPDCC6hevTqaNWuGzz//XOmwykybNm2wa9cu/P333wCA06dP4+DBg+jRo4fCkSnjypUriI+PN9ov2tjYoH379qreL2o0GtW0imZnZyM0NBQTJ05Ew4YNy7x+Pgy1DCQmJkKn08HFxcWo3MXFBfHx8QpFpRwhBMaPH482bdrAz89P6XDKzKZNm3Dy5EkcO3ZM6VAUcfnyZURERGD8+PF49913cfToUYwdOxY2NjYYNGiQ0uGVusmTJyMpKQk+Pj7QarXQ6XT48MMPMXDgQKVDU4R+32dqv3jt2jUlQlJUWloa3nnnHbz00kuqeUDq3LlzYWlpibFjxypSPxOgMqTRaIw+CyHylKnB6NGjcebMGRw8eFDpUMrM9evXMW7cOOzYsQO2trZKh6OI7OxstGjRAnPmzAEANGvWDOfOnUNERIQqEqDNmzfjq6++woYNG9CwYUNERUUhLCwM7u7uGDx4sNLhKYb7Rdkh+sUXX0R2djZWrFihdDhl4sSJE1i8eDFOnjyp2N+bp8DKQNWqVaHVavO09iQkJOT59fOkGzNmDH744Qfs2bMHNWvWVDqcMnPixAkkJCTA398flpaWsLS0xL59+7BkyRJYWlpCp9MpHWKpc3Nzg6+vr1FZgwYNVHMhwMSJE/HOO+/gxRdfRKNGjRAaGoq33noL4eHhSoemCFdXVwBQ/X4xMzMT/fv3x5UrVxAZGama1p8DBw4gISEBtWrVMuwTr127hgkTJsDLy6tMYmACVAasra3h7++PyMhIo/LIyEgEBQUpFFXZEkJg9OjR2LZtG3bv3g1vb2+lQypTnTp1wtmzZxEVFWUYWrRogZdffhlRUVHQarVKh1jqgoOD89z64O+//4anp6dCEZWt1NRUWFgY73K1Wu0TfRl8Qby9veHq6mq0X8zIyMC+fftUs1/UJz///PMPdu7ciSpVqigdUpkJDQ3FmTNnjPaJ7u7umDhxIn777bcyiYGnwMrI+PHjERoaihYtWiAwMBArV65ETEwMRo4cqXRoZWLUqFHYsGEDvv/+ezg6Ohp+9Tk7O8POzk7h6Eqfo6Njnv5ODg4OqFKlimr6Qb311lsICgrCnDlz0L9/fxw9ehQrV67EypUrlQ6tTPTu3RsffvghatWqhYYNG+LUqVNYuHAhhg4dqnRopSYlJQUXL140fL5y5QqioqJQuXJl1KpVC2FhYZgzZw7q1q2LunXrYs6cObC3t8dLL72kYNQlp6D1d3d3R79+/XDy5En89NNP0Ol0hv1i5cqVYW1trVTYJaawv//DCZ+VlRVcXV1Rv379sgmwzK43I7F8+XLh6ekprK2tRfPmzVV1CTgAk8OaNWuUDk0xarsMXgghfvzxR+Hn5ydsbGyEj4+PWLlypdIhlZnk5GQxbtw4UatWLWFraytq164tpk6dKtLT05UOrdTs2bPH5P/94MGDhRDyUvgZM2YIV1dXYWNjI9q1ayfOnj2rbNAlqKD1v3LlSr77xT179igdeoko7O//sLK+DF4jhBBlk2oRERERlQ/sA0RERESqwwSIiIiIVIcJEBEREakOEyAiIiJSHSZAREREpDpMgIiIiEh1mAARERGR6jABIiIiItVhAkRElA+NRoPvvvtO6TCIqBQwASKicmnIkCHQaDR5hm7duikdGhE9AfgwVCIqt7p164Y1a9YYldnY2CgUDRE9SdgCRETllo2NDVxdXY2GSpUqAZCnpyIiItC9e3fY2dnB29sbW7ZsMZr/7NmzePrpp2FnZ4cqVapgxIgRSElJMZpm9erVaNiwIWxsbODm5obRo0cbjU9MTMRzzz0He3t71K1bFz/88INh3J07d/Dyyy+jWrVqsLOzQ926dfMkbERUPjEBIqLH1vTp0/H888/j9OnTeOWVVzBw4ECcP38eAJCamopu3bqhUqVKOHbsGLZs2YKdO3caJTgREREYNWoURowYgbNnz+KHH35AnTp1jOqYNWsW+vfvjzNnzqBHjx54+eWXcfv2bUP90dHR+OWXX3D+/HlERESgatWqZbcBiKj4yuy580REZhg8eLDQarXCwcHBaJg9e7YQQggAYuTIkUbzBAQEiDfeeEMIIcTKlStFpUqVREpKimH8zz//LCwsLER8fLwQQgh3d3cxderUfGMAIKZNm2b4nJKSIjQajfjll1+EEEL07t1bvPrqqyWzwkRUptgHiIjKrY4dOyIiIsKorHLlyob3gYGBRuMCAwMRFRUFADh//jyaNGkCBwcHw/jg4GBkZ2fjwoUL0Gg0uHnzJjp16lRgDI0bNza8d3BwgKOjIxISEgAAb7zxBp5//nmcPHkSXbp0QUhICIKCgoq1rkRUtpgAEVG55eDgkOeUVGE0Gg0AQAhheG9qGjs7uyItz8rKKs+82dnZAIDu3bvj2rVr+Pnnn7Fz50506tQJo0aNwscff2xWzERU9tgHiIgeW3/88Ueezz4+PgAAX19fREVF4f79+4bxhw4dgoWFBerVqwdHR0d4eXlh165djxRDtWrVMGTIEHz11VdYtGgRVq5c+UjLI6KywRYgIiq30tPTER8fb1RmaWlp6Gi8ZcsWtGjRAm3atMH69etx9OhR/O9//wMAvPzyy5gxYwYGDx6MmTNn4r///sOYMWMQGhoKFxcXAMDMmTMxcuRIVK9eHd27d8e9e/dw6NAhjBkzpkjxvffee/D390fDhg2Rnp6On376CQ0aNCjBLUBEpYUJEBGVW7/++ivc3NyMyurXr4+//voLgLxCa9OmTXjzzTfh6uqK9evXw9fXFwBgb2+P3377DePGjUPLli1hb2+P559/HgsXLjQsa/DgwUhLS8Mnn3yCt99+G1WrVkW/fv2KHJ+1tTWmTJmCq1evws7ODm3btsWmTZtKYM2JqLRphBBC6SCIiMyl0Wjw7bffIiQkROlQiOgxxD5AREREpDpMgIiIiEh12AeIiB5LPHtPRI+CLUBERESkOkyAiIiISHWYABEREZHqMAEiIiIi1WECRERERKrDBIiIiIhUhwkQERERqQ4TICIiIlKd/wMkThDrNXy37QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------消耗模型评估分值: ---------\n",
      "accuracy: 0.763\n",
      "ovr macro auc: 0.803\n",
      "ovo macro auc: 0.844\n",
      "ovr weighted auc: 0.837\n",
      "ovo weighted auc: 0.852\n",
      "micro precision: 0.763\n",
      "macro precision: 0.688\n",
      "weighted precision: 0.741\n",
      "micro recall: 0.763\n",
      "macro recall: 0.564\n",
      "weighted recall: 0.763\n",
      "-----------充值模型评估分值: ---------\n",
      "accuracy: 0.970\n",
      "ovr macro auc: 0.810\n",
      "ovo macro auc: 0.878\n",
      "ovr weighted auc: 0.874\n",
      "ovo weighted auc: 0.875\n",
      "micro precision: 0.970\n",
      "macro precision: 0.714\n",
      "weighted precision: 0.960\n",
      "micro recall: 0.970\n",
      "macro recall: 0.397\n",
      "weighted recall: 0.970\n",
      "---------------------------------------- plot and evaluate end ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*40+\" plot and evaluate begin \"+'-'*40)\n",
    "for i in range(len(gamma_values)):\n",
    "    \n",
    "    print(f\"plot for gamma={gamma_values[i]}\")\n",
    "    plot_multitask_accuracies(training_histories[i])\n",
    "\n",
    "    pred_result=np.asarray(predict_results[i])\n",
    "    predict_prob_cost=pred_result[0]\n",
    "    predict_prob_recharge=pred_result[1]\n",
    "    print(\"-----------消耗模型评估分值: ---------\")\n",
    "    evaluate_score(test_cost_label,predict_prob_cost)\n",
    "    print(\"-----------充值模型评估分值: ---------\")\n",
    "    evaluate_score(test_recharge_label,predict_prob_recharge)\n",
    "\n",
    "print('-'*40+\" plot and evaluate end \"+'-'*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb2f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
