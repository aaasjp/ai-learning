{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7809a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import hanlp\n",
    "import pickle\n",
    "import collections\n",
    "import keras\n",
    "import pydot\n",
    "import pydotplus\n",
    "from pydotplus import graphviz\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import jieba\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5845aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_data(file_path,label_cols,text_fea_cols,categorical_fea_cols,numeric_fea_cols,):\n",
    "    df_raw = pd.read_csv(file_path, header=0, error_bad_lines=False, delimiter='\\t', engine='python')    \n",
    "    df_raw.fillna(value=\"\",inplace=True)    \n",
    "    df_no_user=df_raw.iloc[:,1:]\n",
    "    \n",
    "    '''for easy debug'''\n",
    "    #df_no_user=df_no_user.head(3000)\n",
    "\n",
    "    labels=df_no_user.iloc[:,label_cols]\n",
    "    text_fea=df_no_user.iloc[:,text_fea_cols]\n",
    "    categorical_fea=df_no_user.iloc[:,categorical_fea_cols]\n",
    "    numeric_fea=df_no_user.iloc[:,numeric_fea_cols]\n",
    "       \n",
    "    return df_no_user,labels,text_fea,categorical_fea,numeric_fea\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d801fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categorical_fea(df,encoder_path):\n",
    "    import pickle\n",
    "    try:\n",
    "        with open(encoder_path,'rb') as f:\n",
    "            le=pickle.load(f)\n",
    "            print(\"load encoder success!\")\n",
    "    except:\n",
    "        le = LabelEncoder()\n",
    "        print(\"construct a new encoder success!\")\n",
    "    \n",
    "    with open(encoder_path,'wb') as handle:\n",
    "        df_encode=df.apply(le.fit_transform)\n",
    "        pickle.dump(le,handle)\n",
    "        \n",
    "    return df_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b767ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_numeric_fea(df):\n",
    "    df.replace('',0,inplace=True)\n",
    "    x = df.values\n",
    "    '''Attention vs min_max_scale,使用min_max_scale会导致准确率大幅下降，因为min-max映射到[0-1],而standard不是'''\n",
    "    std_scaler = preprocessing.StandardScaler() \n",
    "    x_scaled = std_scaler.fit_transform(x)\n",
    "    return pd.DataFrame(x_scaled,columns = df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ffef5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stop_words(filename):\n",
    "    with open(filename,'r',encoding=\"utf-8\") as f:\n",
    "        stopwords_raw = f.readlines()\n",
    "    return set([stop.strip() for stop in stopwords_raw])\n",
    "    \n",
    "\n",
    "def remove_stop_words(text,stopwords):\n",
    "    text_without_stopwords = []\n",
    "    for tokens in text:\n",
    "        tokens_new=[]\n",
    "        for t in tokens:\n",
    "            if t not in stopwords:\n",
    "                tokens_new.append(t)\n",
    "        text_without_stopwords.append(tokens_new)\n",
    "    return text_without_stopwords\n",
    "\n",
    "def text_regex(text,\n",
    "               regex='[a-zA-Z0-9’!\"#$%&\\'()*（）：；＋－+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~\\s]+'):\n",
    "    text_re=[]\n",
    "    text_re=[re.sub(regex,\"\",t) for t in text]\n",
    "    return text_re\n",
    "\n",
    "def text_seg(text):   \n",
    "    #tok = hanlp.load(hanlp.pretrained.tok.COARSE_ELECTRA_SMALL_ZH)\n",
    "    #text_seg=tok(text)\n",
    "    text_seg=list()\n",
    "    for tst in text:\n",
    "        tst_seg=jieba.cut(tst)\n",
    "        text_seg.append(\" \".join(tst_seg))\n",
    "    stopwords=load_stop_words(\"../config/stopwords.txt\")\n",
    "    #print(\"stopwords=\",stopwords)\n",
    "    text_seg=remove_stop_words(text_seg,stopwords)\n",
    "    return text_seg\n",
    "\n",
    "def get_tokenizer(path,text=None,num_words=5000): \n",
    "    \n",
    "    try:\n",
    "        with open(path, 'rb') as handle:\n",
    "            tokenizer = pickle.load(handle)\n",
    "    except:\n",
    "        tokenizer=Tokenizer(num_words=num_words,oov_token='<OOV>',char_level=False)\n",
    "        tokenizer.fit_on_texts(text)\n",
    "    \"\"\"\n",
    "    比如\n",
    "    num_words=1000，则说明，在输入的index值中，padding=0，oov=1，。。。。。max=999\n",
    "    \"\"\"\n",
    "    print(\"tokenizer.num_words =\",tokenizer.num_words)\n",
    "    print(\"tokenizer.word_counts =\",len(tokenizer.word_counts))\n",
    "    print(\"tokenizer.word_index =\",len(tokenizer.word_index))\n",
    "    return tokenizer\n",
    "\n",
    "def save_tokenizer(tokenizer,path):\n",
    "    with open(path, 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        \n",
    "def process_text_fea(df,num_words=5000,token_path=None,max_len=50,text_matrix=False,matrix_mode='tfidf'):\n",
    "    print(\"num_words=\",num_words)\n",
    "    if len(df.columns.values)!=1:\n",
    "        raise Exception(\"df should has only one text type columns!\")\n",
    "    text=df.values.reshape(df.shape[0]).tolist()\n",
    "    text=text_regex(text)\n",
    "    text=text_seg(text)\n",
    "    text_token=[]\n",
    "    for text_ent in text:\n",
    "        token_str=\"\"\n",
    "        for token in text_ent:\n",
    "            token_str+=token+\" \"\n",
    "        text_token.append(token_str.strip())\n",
    "    \n",
    "    tokenizer=get_tokenizer(path=token_path,text=text_token,num_words=num_words)\n",
    "    '''为了防止不同版本的tokenizer混淆，暂时先不需要保存'''\n",
    "    save_tokenizer(tokenizer,token_path)\n",
    "    \n",
    "    if text_matrix:\n",
    "        text_sequence=tokenizer.texts_to_sequences(texts=text_token)\n",
    "        text_sequence=tokenizer.sequences_to_matrix(sequences=text_sequence,mode=matrix_mode)\n",
    "        print(type(text_sequence))\n",
    "        print(\"text_sequence.shape=\",text_sequence.shape)\n",
    "    else:\n",
    "        text_sequence=tokenizer.texts_to_sequences(texts=text_token)\n",
    "        text_sequence=pad_sequences(sequences=text_sequence,padding=\"post\",maxlen=max_len,truncating='pre')\n",
    "        print(type(text_sequence))\n",
    "        print(\"text_sequence.shape=\",text_sequence.shape)\n",
    "    \n",
    "    text_sequence=np.asarray(text_sequence).tolist()\n",
    "    \n",
    "    return pd.DataFrame({df.columns.values[0]:text_sequence}),tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ec90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_and_feature(train_data,test_data,cost_label_col,recharge_label_col,text_fea_cols,categorical_fea_cols,numeric_fea_cols):\n",
    "    \n",
    "    train_cost_label=train_data[:,cost_label_col]\n",
    "    train_recharge_label=train_data[:,recharge_label_col]\n",
    "    train_text_fea=train_data[:,text_fea_cols]\n",
    "    train_cate_fea=train_data[:,categorical_fea_cols] \n",
    "    train_numeric_fea=train_data[:,numeric_fea_cols]\n",
    "    \n",
    "    test_cost_label=test_data[:,cost_label_col]\n",
    "    test_recharge_label=test_data[:,recharge_label_col]\n",
    "    test_text_fea=test_data[:,text_fea_cols]\n",
    "    test_cate_fea=test_data[:,categorical_fea_cols]\n",
    "    test_numeric_fea=test_data[:,numeric_fea_cols]\n",
    "    \n",
    "    ##此处加上这个是为了解决：Failed to convert a NumPy array to a Tensor (Unsupported object type int).\n",
    "    train_cost_label=np.asarray(train_cost_label).astype('int32')\n",
    "    train_recharge_label=np.asarray(train_recharge_label).astype('int32')\n",
    "    train_cate_fea=np.asarray(train_cate_fea).astype('int32')\n",
    "    train_numeric_fea=np.asarray(train_numeric_fea).astype('float32') ##float not int !!\n",
    "    \n",
    "    '''\n",
    "    单独处理train_text_fea，因为里面的元素是list，没法直接用上述方式转成int32\n",
    "    '''\n",
    "    train_text_fea=np.reshape(train_text_fea,(train_text_fea.shape[0],))\n",
    "    train_text_fea_convert=[]\n",
    "    for item in train_text_fea:\n",
    "        train_text_fea_convert.append(np.asarray(item))\n",
    "    train_text_fea=np.asarray(train_text_fea_convert).astype('int32')\n",
    "           \n",
    "    test_cost_label=np.asarray(test_cost_label).astype('int32')\n",
    "    test_recharge_label=np.asarray(test_recharge_label).astype('int32')\n",
    "    test_cate_fea=np.asarray(test_cate_fea).astype('int32')\n",
    "    test_numeric_fea=np.asarray(test_numeric_fea).astype('float32') ##float not int !!\n",
    "    \n",
    "    '''\n",
    "    单独处理test_text_fea，因为里面的元素是list，没法直接用上述方式转成int32\n",
    "    '''\n",
    "    test_text_fea=np.reshape(test_text_fea,(test_text_fea.shape[0],))\n",
    "    test_text_fea_convert=[]\n",
    "    for item in test_text_fea:\n",
    "        test_text_fea_convert.append(np.asarray(item))\n",
    "    test_text_fea=np.asarray(test_text_fea_convert).astype('int32')\n",
    "    \n",
    "    return train_cost_label,train_recharge_label,train_text_fea,train_cate_fea,train_numeric_fea,test_cost_label,test_recharge_label,test_text_fea,test_cate_fea,test_numeric_fea\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e717bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(df,original=True,all_label_cols=None,label_col=None,label_values=None,label_counts=None,repeat_noise_ratio=0.95,sample_noise_ratio=0.95):\n",
    "    \n",
    "    print('-'*10+\"label counts in all data\"+'-'*10)   \n",
    "    for lc in all_label_cols:\n",
    "        print('label: ',lc)\n",
    "        print(df_data.iloc[:,lc].value_counts())\n",
    "          \n",
    "    \n",
    "    data=df.values  \n",
    "    train_data,test_data=train_test_split(data,test_size=0.1)   \n",
    "    \n",
    "    if original==False:\n",
    "        if len(label_values)!=len(label_counts):\n",
    "            raise ValueError(\"list label_values'size isn't equal to list label_counts!\")\n",
    "        if len(np.unique(train_data[:,label_col]))!=len(label_counts):\n",
    "            raise ValueError(\"df data dosen't has all label type!\")\n",
    "        \n",
    "        print('-'*10+\"label counts in train data BEFORE sample|repeat|noise\"+'-'*10) \n",
    "        for lc in all_label_cols:\n",
    "            print('label: ',lc)\n",
    "            print(collections.Counter(train_data[:,lc]))\n",
    "            \n",
    "        train_data_dict={}\n",
    "        for i in label_values:\n",
    "            lv=label_values[i]\n",
    "            lc=label_counts[i]\n",
    "            #td=train_data[np.in1d(train_data[:, label_col], lv)]\n",
    "            td=train_data[np.equal(train_data[:, label_col], lv)]\n",
    "            td_other=train_data[np.not_equal(train_data[:, label_col], lv)]\n",
    "            if td.shape[0]>=lc:\n",
    "                print(\"label value=\",lv,\" more than need! need=\",lc,\" exist=\",td.shape[0])\n",
    "                noise_counts=math.ceil(lc*(1-sample_noise_ratio))\n",
    "                noise_idxs=np.random.randint(td_other.shape[0],size=min(noise_counts,td_other.shape[0]))\n",
    "                noise_td=td_other[noise_idxs,:]\n",
    "                print(\"noise data counts=\",noise_td.shape[0])\n",
    "                noise_td[:,label_col]=lv\n",
    "                               \n",
    "                sample_counts=lc-noise_td.shape[0]\n",
    "                sample_idxs=np.random.randint(td.shape[0],size=sample_counts)\n",
    "                sample_td=td[sample_idxs,:]\n",
    "                print(\"sample data counts=\",sample_td.shape[0])\n",
    "               \n",
    "                merge_td=np.concatenate((sample_td,noise_td),axis=0)\n",
    "                train_data_dict[lv]=np.asarray(merge_td)\n",
    "            elif td.shape[0]<lc:\n",
    "                print(\"label value=\",lv,\" less than need! need=\",lc,\" exist=\",td.shape[0])\n",
    "                lack_counts=lc-td.shape[0]\n",
    "                print(\"lack_counts=\",lack_counts)\n",
    "                noise_counts=math.ceil(lack_counts*(1-repeat_noise_ratio))\n",
    "                noise_idxs=np.random.randint(td_other.shape[0],size=noise_counts)\n",
    "                noise_td=td_other[noise_idxs,:]\n",
    "                print(\"noise data counts=\",noise_td.shape[0])\n",
    "                noise_td[:,label_col]=lv\n",
    "                \n",
    "                repeat_counts=lc-noise_counts\n",
    "                repeat_times=math.ceil(repeat_counts/td.shape[0])\n",
    "                repeat_td=np.repeat(td,repeat_times+2,axis=0)\n",
    "                \n",
    "                sample_idxs=np.random.randint(repeat_td.shape[0],size=repeat_counts)\n",
    "                repeat_td=repeat_td[sample_idxs,:]\n",
    "                print(\"repeat data counts=\",repeat_td.shape[0])\n",
    "                \n",
    "                merge_td=np.concatenate((repeat_td,noise_td),axis=0)\n",
    "                train_data_dict[lv]=np.asarray(merge_td)\n",
    "                \n",
    "        train_data=np.concatenate(list(train_data_dict.values()),axis=0)\n",
    "        print('-'*10+\"label counts in train data AFTER sample|repeat|noise\"+'-'*10) \n",
    "        for lc in all_label_cols:\n",
    "            print('label: ',lc)\n",
    "            print(collections.Counter(train_data[:,lc]))\n",
    "    \n",
    "    print(\"train_data.shape=\",train_data.shape)\n",
    "    print('-'*10+\"splited data counts\"+'-'*10)   \n",
    "    print('train:',train_data.shape)\n",
    "    print('test:',test_data.shape)\n",
    "    \n",
    "    return train_data,test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2fbb4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pre_trained_embedding(embedd_file):\n",
    "    pre_trained_embed={}\n",
    "    with open(embedd_file,'rb') as handle:\n",
    "        next(handle)\n",
    "        for line in handle:\n",
    "            values = line.split()\n",
    "            word = values[0].decode('utf-8')\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            pre_trained_embed[word] = coefs\n",
    "    \n",
    "    words_size=len(pre_trained_embed)\n",
    "    embed_size=len(pre_trained_embed[list(pre_trained_embed.keys())[0]])\n",
    "    print(f\"there are {words_size} words,every word has {embed_size} dimension\")\n",
    "    return pre_trained_embed\n",
    "\n",
    "\n",
    "def init_embed_with_pre_trained(tokenizer,pre_trained_embed): \n",
    "    embed_size=len(pre_trained_embed[list(pre_trained_embed.keys())[0]])\n",
    "    \n",
    "    '''此处是voca_size好，还是num_words好，为了节约空间，还是使用num_words吧'''\n",
    "    \n",
    "    voca_size=len(tokenizer.word_index)+1\n",
    "    embedding_matrix = np.zeros((voca_size, embed_size))\n",
    "    \n",
    "    #embedding_matrix = np.zeros((tokenizer.num_words, embed_size))\n",
    "    \n",
    "    hits=0\n",
    "    miss=0\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        embedding_vector = pre_trained_embed.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            hits+=1\n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "        else:\n",
    "            miss+=1\n",
    "    print(\"hits=\",hits)\n",
    "    print(\"miss=\",miss)\n",
    "    return embedding_matrix\n",
    "\n",
    "def init_embed_with_pre_trained_2(tokenizer,pre_trained_embed): \n",
    "    embed_size=len(pre_trained_embed[list(pre_trained_embed.keys())[0]])\n",
    "    \n",
    "    '''此处是voca_size好，还是num_words好，为了节约空间，还是使用num_words吧'''\n",
    "    \n",
    "    #voca_size=len(tokenizer.word_index)+1\n",
    "    #embedding_matrix = np.zeros((voca_size, embed_size))\n",
    "    \n",
    "    embedding_matrix = np.zeros((tokenizer.num_words, embed_size))\n",
    "    \n",
    "    hits=0\n",
    "    miss=0\n",
    "    effect_hits=0\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        embedding_vector = pre_trained_embed.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            hits+=1\n",
    "            if idx<tokenizer.num_words:\n",
    "                effect_hits+=1\n",
    "                embedding_matrix[idx] = embedding_vector\n",
    "        else:\n",
    "            miss+=1\n",
    "    print(\"hits=\",hits)\n",
    "    print(\"miss=\",miss)\n",
    "    print(\"effect_hits=\",effect_hits)\n",
    "    return embedding_matrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df51f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_block_of_model(max_sequence_length,num_words,text_embed_size,lstm_size):\n",
    "    inputs=tf.keras.layers.Input(shape=(max_sequence_length,),dtype=tf.int32,name='text_inputs')\n",
    "    print(\"text embed's input size=\",num_words)\n",
    "    embed_outputs=tf.keras.layers.Embedding(input_dim=num_words, output_dim=text_embed_size, input_length=max_sequence_length,embeddings_initializer=tf.initializers.random_normal)(inputs)\n",
    "    #lstm_outputs=Bidirectional(LSTM(lstm_size,activation=\"relu\",dropout=0.2,return_sequences=True))(embed_outputs)\n",
    "    lstm_outputs=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size,activation=\"relu\",dropout=0.2,return_sequences=False))(embed_outputs)\n",
    "    '''add batchnorm,to normlize the output for the same scale with numeric'''\n",
    "    norm_outputs=tf.keras.layers.BatchNormalization()(lstm_outputs)\n",
    "    return inputs,norm_outputs\n",
    "\n",
    "def text_block_of_model_text_matrix(num_words=5000,dense_size=100):\n",
    "    print(\"num_words=\",num_words)\n",
    "    inputs=tf.keras.layers.Input(shape=(num_words,),dtype=tf.float32,name='text_inputs')\n",
    "    #print(inputs.shape)\n",
    "    norm_outputs_1=tf.keras.layers.BatchNormalization()(inputs)\n",
    "    dense_outputs=tf.keras.layers.Dense(dense_size, activation='sigmoid')(norm_outputs_1)\n",
    "    norm_outputs_2=tf.keras.layers.BatchNormalization()(dense_outputs)\n",
    "    return inputs,norm_outputs_2\n",
    "\n",
    "def text_block_of_model_pre_trained(max_sequence_length,lstm_size,embedding_matrix):\n",
    "    voca_size=embedding_matrix.shape[0] ##包括padding和oov，num_words,只是保证输入的index是【0，num_words-1】\n",
    "    text_embed_size=embedding_matrix.shape[1]\n",
    "    inputs=tf.keras.layers.Input(shape=(max_sequence_length,),dtype=tf.int32,name='text_inputs')\n",
    "    print(f\"voca_size={voca_size},text_embed_size={text_embed_size}\")\n",
    "    embed_outputs=tf.keras.layers.Embedding(input_dim=voca_size, output_dim=text_embed_size, input_length=max_sequence_length,embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),trainable=False)(inputs)\n",
    "    #lstm_outputs=Bidirectional(LSTM(lstm_size,activation=\"relu\",dropout=0.2,return_sequences=True))(embed_outputs)\n",
    "    lstm_outputs=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size,activation=\"relu\",dropout=0.2,return_sequences=False))(embed_outputs)\n",
    "    '''add batchnorm,to normlize the output for the same scale with numeric'''\n",
    "    norm_outputs=tf.keras.layers.BatchNormalization()(lstm_outputs)\n",
    "    return inputs,norm_outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed32afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cate_block_of_model(cate_num_sizes,cate_embed_sizes):\n",
    "    inputs=[]\n",
    "    outputs=[]\n",
    "    if len(cate_num_sizes)!=len(cate_embed_sizes):\n",
    "        raise ValueError(\"cate size!= embed size!\")\n",
    "    for i in range(len(cate_num_sizes)):\n",
    "        inpt = tf.keras.layers.Input(shape=(1,),dtype=tf.int32,name='cate_inputs_'+str(i))\n",
    "        inputs.append(inpt)\n",
    "        print(\"cate \"+str(i)+\" size:cate_num_sizes=\",str(cate_num_sizes[i])+\" \")\n",
    "        embed = tf.keras.layers.Embedding(cate_num_sizes[i],cate_embed_sizes[i], trainable=True,embeddings_initializer=tf.initializers.random_normal)(inpt)\n",
    "        embed_rehsaped =tf.keras.layers.Reshape(target_shape=(cate_embed_sizes[i],))(embed)\n",
    "        outputs.append(embed_rehsaped)  \n",
    "    concate_outputs=tf.keras.layers.concatenate(outputs)\n",
    "    '''add batchnorm,to normlize the output for the same scale with numeric'''\n",
    "    norm_outputs=tf.keras.layers.BatchNormalization()(concate_outputs)\n",
    "    return inputs,norm_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91774250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_block_of_model(input_size,dense_size):\n",
    "    inputs=tf.keras.layers.Input(shape=(input_size,),dtype=tf.float32,name='numeric_inputs')\n",
    "    dense_outputs=tf.keras.layers.Dense(dense_size, activation='relu')(inputs)\n",
    "    norm_outputs=tf.keras.layers.BatchNormalization()(dense_outputs)\n",
    "    return inputs,norm_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d787cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_task_learning_model(cate_num_sizes,cate_embed_sizes,\n",
    "                                     numeric_input_size=200,numeric_dense_size=50,\n",
    "                                     text_max_sequence_length=50,\n",
    "                                     text_num_words=5000,\n",
    "                                     text_embed_size=100,\n",
    "                                     text_dense_size=40,\n",
    "                                     text_lstm_size=20,\n",
    "                                     text_matrix=False,\n",
    "                                     is_pre_trained=False,\n",
    "                                     inited_embedd_matrix=None):\n",
    "    \n",
    "    cate_inputs,cate_outputs=cate_block_of_model(cate_num_sizes,cate_embed_sizes)\n",
    "    if text_matrix:\n",
    "        text_inputs,text_outputs=text_block_of_model_text_matrix(num_words=text_num_words,dense_size=text_dense_size)  \n",
    "    else:\n",
    "        if is_pre_trained:\n",
    "            text_inputs,text_outputs=text_block_of_model_pre_trained(max_sequence_length=text_max_sequence_length,lstm_size=text_lstm_size,embedding_matrix=inited_embedd_matrix)\n",
    "        else:\n",
    "            text_inputs,text_outputs=text_block_of_model(max_sequence_length=text_max_sequence_length,num_words=text_num_words,text_embed_size=text_embed_size,lstm_size=text_lstm_size)\n",
    "        \n",
    "    numeric_inputs,numeric_outputs=numeric_block_of_model(input_size=numeric_input_size,dense_size=numeric_dense_size)\n",
    "    \n",
    "    outputs=tf.keras.layers.concatenate([cate_outputs,text_outputs,numeric_outputs])\n",
    "    outputs=tf.keras.layers.BatchNormalization()(outputs)\n",
    "    outputs=tf.keras.layers.Dense(60, activation='relu')(outputs)\n",
    "    outputs=tf.keras.layers.BatchNormalization()(outputs)\n",
    "    \n",
    "    outputs_cost=tf.keras.layers.Dense(20, activation='relu')(outputs)\n",
    "    outputs_cost=tf.keras.layers.BatchNormalization()(outputs_cost)\n",
    "    outputs_cost=tf.keras.layers.Dense(3, activation='softmax',name='outputs_cost')(outputs_cost)\n",
    "    \n",
    "    outputs_recharge=tf.keras.layers.Dense(20, activation='relu')(outputs)\n",
    "    outputs_recharge=tf.keras.layers.BatchNormalization()(outputs_recharge)\n",
    "    outputs_recharge=tf.keras.layers.Dense(3, activation='softmax',name='outputs_recharge')(outputs_recharge)\n",
    "    \n",
    "    model = Model(inputs=cate_inputs+[text_inputs,numeric_inputs], outputs=[outputs_cost,outputs_recharge])\n",
    "    \n",
    "    #model.summary()\n",
    "    tf.keras.utils.plot_model(model, to_file=model_architecture_image,show_shapes=True,show_dtype=True,show_layer_activations=True)\n",
    "    \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4076b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_multitask_model(model, gamma):\n",
    "        \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'outputs_cost': 'sparse_categorical_crossentropy', \n",
    "                        'outputs_recharge': 'sparse_categorical_crossentropy'},\n",
    "                  loss_weights={'outputs_cost': gamma, \n",
    "                                'outputs_recharge': 1 - gamma}, \n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5805604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_batch(model):  \n",
    "    start = time.time()\n",
    "    history =model.fit(x={'cate_inputs_0': train_cate_fea[:,0],\n",
    "                          'cate_inputs_1': train_cate_fea[:,1],\n",
    "                          'cate_inputs_2': train_cate_fea[:,2],\n",
    "                          'text_inputs': train_text_fea,\n",
    "                          'numeric_inputs':train_numeric_fea},\n",
    "                       y={'outputs_cost': train_cost_label,\n",
    "                          'outputs_recharge': train_recharge_label},\n",
    "                       validation_split=0.1,\n",
    "                       epochs=10, \n",
    "                       batch_size=32, \n",
    "                       verbose=1)\n",
    "    print(f'Training time: {time.time() - start}\\n')\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9713fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multitask_accuracies(training_history):\n",
    "    \n",
    "    plt.plot(range(len(history.history['outputs_cost_accuracy'])), history.history['outputs_cost_accuracy'], c='r', label='Cost')\n",
    "    plt.plot(range(len(history.history['outputs_recharge_accuracy'])), history.history['outputs_recharge_accuracy'], c='b', label='Recharge')\n",
    "\n",
    "    plt.plot(range(len(history.history['val_outputs_cost_accuracy'])), history.history['val_outputs_cost_accuracy'], c='r',linestyle='dashed', marker='o', label='Val-Cost')\n",
    "    plt.plot(range(len(history.history['val_outputs_recharge_accuracy'])), history.history['val_outputs_recharge_accuracy'], c='b', linestyle='dashed', marker='o', label='Val-Recharge')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7803f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_score(y_true,y_pred_prob):\n",
    "    pred_label=np.asarray([np.argmax(v) for v in y_pred_prob])\n",
    "    print('accuracy: %.3f' % accuracy_score(y_true, pred_label))\n",
    "    print('ovr macro auc: %.3f' % roc_auc_score(y_true, y_pred_prob,multi_class='ovo',average='macro')) #注意这里是prob\n",
    "    print('ovo macro auc: %.3f' % roc_auc_score(y_true, y_pred_prob, multi_class='ovr',average='macro')) #注意这里是prob\n",
    "    print('ovr weighted auc: %.3f' % roc_auc_score(y_true, y_pred_prob,multi_class='ovo',average='weighted')) #注意这里是prob\n",
    "    print('ovo weighted auc: %.3f' % roc_auc_score(y_true, y_pred_prob, multi_class='ovr',average='weighted')) #注意这里是prob\n",
    "    print('micro precision: %.3f' % precision_score(y_true, pred_label,average='micro'))\n",
    "    print('macro precision: %.3f' % precision_score(y_true, pred_label,average='macro'))\n",
    "    print('weighted precision: %.3f' % precision_score(y_true, pred_label,average='weighted'))\n",
    "    print('micro recall: %.3f' % recall_score(y_true, pred_label,average='micro'))\n",
    "    print('macro recall: %.3f' % recall_score(y_true, pred_label,average='macro'))\n",
    "    print('weighted recall: %.3f' % recall_score(y_true, pred_label,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60831173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** Multi-Task-Model Begin Running ******************************************************\n",
      "\n",
      "\n",
      "---------------------------------------- load data begin ----------------------------------------\n",
      "df_no_user.shape= (1000000, 271)\n",
      "labels.shape= (1000000, 2)\n",
      "text_fea.shape= (1000000, 1)\n",
      "categorical_fea.shape= (1000000, 3)\n",
      "numeric_fea.shape= (1000000, 265)\n",
      "   c_label  r_label                                    problem_content  \\\n",
      "0        2        2  采购员客服发布招聘信息刷新优化#电话联系 设置采购 客服精品刷新 效果不好 建议客户多发帖#...   \n",
      "\n",
      "   main_belong_loc1  main_belong_cate2 main_city_hierarchy  free_money_avg_1d  \\\n",
      "0              7578               3112                  二线                0.0   \n",
      "\n",
      "   free_money_avg_3d  free_money_avg_7d  free_money_avg_14d  ...  \\\n",
      "0           0.002022           0.006067            0.013146  ...   \n",
      "\n",
      "   m_login_counts_60d  sum_senti_score_latest_3month  \\\n",
      "0                   0                       1.184329   \n",
      "\n",
      "   count_senti_score_latest_3mont  avg_score_latest_3month  \\\n",
      "0                               6                 0.197388   \n",
      "\n",
      "   sum_senti_score_latest_6month  count_senti_score_latest_6mont  \\\n",
      "0                       3.911437                              12   \n",
      "\n",
      "   avg_score_latest_6month  sum_senti_score_latest_1year  \\\n",
      "0                 0.325953                      6.237927   \n",
      "\n",
      "   count_senti_score_latest_1year  avg_score_latest_1year  \n",
      "0                              20                0.311896  \n",
      "\n",
      "[1 rows x 271 columns]\n",
      "---------------------------------------- load data end ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('*'*27+\" Multi-Task-Model Begin Running \"+'**'*27+\"\\n\\n\")\n",
    "\n",
    "print('-'*40+\" load data begin \"+'-'*40)\n",
    "label_cols=[0,1]\n",
    "cost_label_col=0\n",
    "recharge_label_col=1\n",
    "text_fea_cols=[2]\n",
    "categorical_fea_cols=[3,4,5]\n",
    "numeric_fea_cols=list(range(6,271))\n",
    "recharge_label_values=[0,1,2]\n",
    "\n",
    "'''--tuning params--'''\n",
    "recharge_label_counts=[30000,100000,600000]\n",
    "is_raw=False\n",
    "gamma_values=[0.5]\n",
    "is_pre_trained=True\n",
    "text_matrix=False\n",
    "train_epochs=15\n",
    "repeat_noise_ratio=1\n",
    "sample_noise_ratio=1\n",
    "num_words=4000\n",
    "token_path=\"../tokenizer/tokenizer_4.2.3.online.pickle\" #Attention,别跟别的模型乱了词表，所以此处要specific\n",
    "max_sequence_len=30\n",
    "data_file=\"../data/train_data_nlp_and_number_and_category_and_sentiments_feature_multi_label__extra_large.txt\"\n",
    "embedd_file=\"../pretrain_embedd/sgns.zhihu.word\"\n",
    "model_architecture_image='../model/model_4.2.3.online.png'\n",
    "encoder_path=\"../category/cate_encoder_4.2.3.online.pickle\"\n",
    "'''--tuning params--'''\n",
    "\n",
    "numeric_input_size=len(numeric_fea_cols)\n",
    "\n",
    "df_no_user,labels,text_fea,categorical_fea,numeric_fea=process_raw_data(\n",
    "    file_path=data_file,\n",
    "    label_cols=label_cols,\n",
    "    text_fea_cols=text_fea_cols,\n",
    "    categorical_fea_cols=categorical_fea_cols,\n",
    "    numeric_fea_cols=numeric_fea_cols\n",
    "    )\n",
    "\n",
    "print(\"df_no_user.shape=\",df_no_user.shape)\n",
    "print(\"labels.shape=\",labels.shape)\n",
    "print(\"text_fea.shape=\",text_fea.shape)\n",
    "print(\"categorical_fea.shape=\",categorical_fea.shape)\n",
    "print(\"numeric_fea.shape=\",numeric_fea.shape)\n",
    "print(df_no_user.head(1))\n",
    "print('-'*40+\" load data end \"+'-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c129b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "三线     346548\n",
       "二线     267099\n",
       "四线     219389\n",
       "五线      83190\n",
       "新一线     73491\n",
       "一线       4221\n",
       "省直       3798\n",
       "其他       2259\n",
       "港澳台         5\n",
       "Name: main_city_hierarchy, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_user['main_city_hierarchy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69c140d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- process feature begin ----------------------------------------\n",
      "num_words= 4000\n",
      "tokenizer.num_words = 4000\n",
      "tokenizer.word_counts = 3542\n",
      "tokenizer.word_index = 3543\n",
      "<class 'numpy.ndarray'>\n",
      "text_sequence.shape= (1000000, 30)\n",
      "load encoder success!\n",
      "(1000000, 271)\n",
      "   c_label  r_label                                    problem_content  \\\n",
      "0        2        2  [31, 720, 304, 2, 125, 70, 68, 41, 17, 83, 85,...   \n",
      "\n",
      "   main_belong_loc1  main_belong_cate2  main_city_hierarchy  \\\n",
      "0               444                135                    2   \n",
      "\n",
      "   free_money_avg_1d  free_money_avg_3d  free_money_avg_7d  \\\n",
      "0           -0.14997          -0.221571          -0.296424   \n",
      "\n",
      "   free_money_avg_14d  ...  m_login_counts_60d  sum_senti_score_latest_3month  \\\n",
      "0           -0.380058  ...           -0.020562                       -0.40815   \n",
      "\n",
      "   count_senti_score_latest_3mont  avg_score_latest_3month  \\\n",
      "0                       -0.147302                -0.464747   \n",
      "\n",
      "   sum_senti_score_latest_6month  count_senti_score_latest_6mont  \\\n",
      "0                       0.150605                        0.093285   \n",
      "\n",
      "   avg_score_latest_6month  sum_senti_score_latest_1year  \\\n",
      "0                 0.078633                      0.180491   \n",
      "\n",
      "   count_senti_score_latest_1year  avg_score_latest_1year  \n",
      "0                        0.226309               -0.076606  \n",
      "\n",
      "[1 rows x 271 columns]\n",
      "----------label counts in all data----------\n",
      "label:  0\n",
      "2    678125\n",
      "1    196610\n",
      "0    125265\n",
      "Name: c_label, dtype: int64\n",
      "label:  1\n",
      "2    968061\n",
      "1     21319\n",
      "0     10620\n",
      "Name: r_label, dtype: int64\n",
      "----------label counts in train data BEFORE sample|repeat|noise----------\n",
      "label:  0\n",
      "Counter({2: 610382, 1: 176922, 0: 112696})\n",
      "label:  1\n",
      "Counter({2: 871290, 1: 19189, 0: 9521})\n",
      "label value= 0  less than need! need= 30000  exist= 9521\n",
      "lack_counts= 20479\n",
      "noise data counts= 0\n",
      "repeat data counts= 30000\n",
      "label value= 1  less than need! need= 100000  exist= 19189\n",
      "lack_counts= 80811\n",
      "noise data counts= 0\n",
      "repeat data counts= 100000\n",
      "label value= 2  more than need! need= 600000  exist= 871290\n",
      "noise data counts= 0\n",
      "sample data counts= 600000\n",
      "----------label counts in train data AFTER sample|repeat|noise----------\n",
      "label:  0\n",
      "Counter({2: 441413, 1: 160934, 0: 127653})\n",
      "label:  1\n",
      "Counter({2: 600000, 1: 100000, 0: 30000})\n",
      "train_data.shape= (730000, 271)\n",
      "----------splited data counts----------\n",
      "train: (730000, 271)\n",
      "test: (100000, 271)\n",
      "---------------------------------------- process feature end ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*40+\" process feature begin \"+'-'*40)\n",
    "\n",
    "df_text_token,tokenizer=process_text_fea(df=text_fea,num_words=num_words,token_path=token_path,max_len=max_sequence_len,text_matrix=text_matrix) \n",
    "df_categorical_fea_enc=process_categorical_fea(categorical_fea,encoder_path)\n",
    "df_numeric_fea_scale=process_numeric_fea(numeric_fea)\n",
    "\n",
    "df_data=pd.concat([labels,df_text_token,df_categorical_fea_enc,df_numeric_fea_scale],axis=1)\n",
    "print(df_data.shape)\n",
    "print(df_data.head(1))\n",
    "\n",
    "if is_raw:\n",
    "    train_data,test_data=split_train_test_data(df_data,all_label_cols=label_cols,original=True)\n",
    "else:\n",
    "    train_data,test_data=split_train_test_data(df_data,all_label_cols=label_cols,original=False,\n",
    "                                               label_col=recharge_label_col,label_values=recharge_label_values,label_counts=recharge_label_counts,\n",
    "                                               repeat_noise_ratio=repeat_noise_ratio,sample_noise_ratio=sample_noise_ratio)\n",
    "\n",
    "print('-'*40+\" process feature end \"+'-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d385c507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- process pretrained embedding begin ----------------------------------------\n",
      "there are 259869 words,every word has 300 dimension\n",
      "hits= 3434\n",
      "miss= 109\n",
      "effect_hits= 3434\n",
      "inited_embedd_matrix.shape= (4000, 300)\n",
      "---------------------------------------- process pretrained embedding end ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*40+\" process pretrained embedding begin \"+'-'*40)\n",
    "pre_trained_embed=get_pre_trained_embedding(embedd_file=embedd_file)\n",
    "inited_embedd_matrix=init_embed_with_pre_trained_2(tokenizer=tokenizer,pre_trained_embed=pre_trained_embed)\n",
    "print(\"inited_embedd_matrix.shape=\",inited_embedd_matrix.shape)\n",
    "print('-'*40+\" process pretrained embedding end \"+'-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "946ce8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- process label and feature begin ----------------------------------------\n",
      "train_cost_label.shape= (730000,)\n",
      "train_recharge_label.shape= (730000,)\n",
      "train_text_fea.shape= (730000, 30)\n",
      "train_cate_fea.shape= (730000, 3)\n",
      "train_numeric_fea.shape= (730000, 265)\n",
      "test_cost_label.shape= (100000,)\n",
      "test_recharge_label.shape= (100000,)\n",
      "test_text_fea.shape= (100000, 30)\n",
      "test_cate_fea.shape= (100000, 3)\n",
      "test_numeric_fea.shape= (100000, 265)\n",
      "---------------------------------------- process label and feature end ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*40+\" process label and feature begin \"+'-'*40)\n",
    "train_cost_label,train_recharge_label,train_text_fea,train_cate_fea,train_numeric_fea,test_cost_label,test_recharge_label,test_text_fea,test_cate_fea,test_numeric_fea=get_label_and_feature(\n",
    "    train_data,test_data,\n",
    "    cost_label_col,recharge_label_col,\n",
    "    text_fea_cols,categorical_fea_cols,numeric_fea_cols)\n",
    "\n",
    "print(\"train_cost_label.shape=\",train_cost_label.shape)\n",
    "print(\"train_recharge_label.shape=\",train_recharge_label.shape)\n",
    "print(\"train_text_fea.shape=\",train_text_fea.shape)\n",
    "print(\"train_cate_fea.shape=\",train_cate_fea.shape)\n",
    "print(\"train_numeric_fea.shape=\",train_numeric_fea.shape)\n",
    "\n",
    "print(\"test_cost_label.shape=\",test_cost_label.shape)\n",
    "print(\"test_recharge_label.shape=\",test_recharge_label.shape)\n",
    "print(\"test_text_fea.shape=\",test_text_fea.shape)\n",
    "print(\"test_cate_fea.shape=\",test_cate_fea.shape)\n",
    "print(\"test_numeric_fea.shape=\",test_numeric_fea.shape)\n",
    "\n",
    "print('-'*40+\" process label and feature end \"+'-'*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f4925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- train model begin ----------------------------------------\n",
      "train model for gamma=0.5\n",
      "cate 0 size:cate_num_sizes= 666 \n",
      "cate 1 size:cate_num_sizes= 181 \n",
      "cate 2 size:cate_num_sizes= 9 \n",
      "voca_size=4000,text_embed_size=300\n",
      "Epoch 1/10\n",
      "20532/20532 [==============================] - 527s 25ms/step - loss: 0.5781 - outputs_cost_loss: 0.7338 - outputs_recharge_loss: 0.4224 - outputs_cost_accuracy: 0.6904 - outputs_recharge_accuracy: 0.8473 - val_loss: 0.3967 - val_outputs_cost_loss: 0.6551 - val_outputs_recharge_loss: 0.1383 - val_outputs_cost_accuracy: 0.7344 - val_outputs_recharge_accuracy: 0.9757\n",
      "Epoch 2/10\n",
      "19826/20532 [===========================>..] - ETA: 17s - loss: 0.5426 - outputs_cost_loss: 0.7022 - outputs_recharge_loss: 0.3830 - outputs_cost_accuracy: 0.7052 - outputs_recharge_accuracy: 0.8580"
     ]
    }
   ],
   "source": [
    "\n",
    "print('-'*40+\" train model begin \"+'-'*40)\n",
    "\n",
    "cate_num_sizes=[]\n",
    "cate_embed_sizes=[]\n",
    "for c in categorical_fea_cols:\n",
    "    cs=train_data[:,c].max()+1 #attention +1 begin because from zero!!!    \n",
    "    cate_num_sizes.append(cs)\n",
    "    cate_embed_sizes.append(math.ceil(cs/20)+2)\n",
    "\n",
    "trained_models=list()\n",
    "training_histories=list()\n",
    "predict_results=list()\n",
    "for i in range(len(gamma_values)):\n",
    "    print(f\"train model for gamma={gamma_values[i]}\")\n",
    "    \n",
    "    model=create_multi_task_learning_model(cate_num_sizes=cate_num_sizes,\n",
    "                                           cate_embed_sizes=cate_embed_sizes,\n",
    "                                           text_max_sequence_length=max_sequence_len,\n",
    "                                           text_num_words=num_words,\n",
    "                                           text_embed_size=100,\n",
    "                                           text_dense_size=40,\n",
    "                                           text_lstm_size=20,\n",
    "                                           numeric_input_size=numeric_input_size,\n",
    "                                           numeric_dense_size=50,\n",
    "                                           text_matrix=text_matrix,\n",
    "                                           is_pre_trained=is_pre_trained,\n",
    "                                           inited_embedd_matrix=inited_embedd_matrix)\n",
    "    compile_multitask_model(model,gamma_values[i])\n",
    "    history=fit_batch(model)\n",
    "\n",
    "    pred_result=model.predict(x={'cate_inputs_0': test_cate_fea[:,0],\n",
    "                                    'cate_inputs_1': test_cate_fea[:,1],\n",
    "                                    'cate_inputs_2': test_cate_fea[:,2],\n",
    "                                    'text_inputs': test_text_fea,\n",
    "                                    'numeric_inputs':test_numeric_fea}\n",
    "                                 ,verbose=1,use_multiprocessing=True)\n",
    "    trained_models.append(model)\n",
    "    training_histories.append(history)\n",
    "    predict_results.append(pred_result)\n",
    "    \n",
    "print('-'*40+\" train model end \"+'-'*40)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "604b0eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- plot and evaluate begin ----------------------------------------\n",
      "plot for gamma=0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------消耗模型评估分值: ---------\n",
      "accuracy: 0.743\n",
      "ovr macro auc: 0.784\n",
      "ovo macro auc: 0.815\n",
      "ovr weighted auc: 0.811\n",
      "ovo weighted auc: 0.824\n",
      "micro precision: 0.743\n",
      "macro precision: 0.637\n",
      "weighted precision: 0.713\n",
      "micro recall: 0.743\n",
      "macro recall: 0.552\n",
      "weighted recall: 0.743\n",
      "-----------充值模型评估分值: ---------\n",
      "accuracy: 0.938\n",
      "ovr macro auc: 0.827\n",
      "ovo macro auc: 0.873\n",
      "ovr weighted auc: 0.869\n",
      "ovo weighted auc: 0.873\n",
      "micro precision: 0.938\n",
      "macro precision: 0.464\n",
      "weighted precision: 0.957\n",
      "micro recall: 0.938\n",
      "macro recall: 0.549\n",
      "weighted recall: 0.938\n",
      "---------------------------------------- plot and evaluate end ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*40+\" plot and evaluate begin \"+'-'*40)\n",
    "for i in range(len(gamma_values)):\n",
    "    \n",
    "    print(f\"plot for gamma={gamma_values[i]}\")\n",
    "    plot_multitask_accuracies(training_histories[i])\n",
    "\n",
    "    pred_result=np.asarray(predict_results[i])\n",
    "    predict_prob_cost=pred_result[0]\n",
    "    predict_prob_recharge=pred_result[1]\n",
    "    print(\"-----------消耗模型评估分值: ---------\")\n",
    "    evaluate_score(test_cost_label,predict_prob_cost)\n",
    "    print(\"-----------充值模型评估分值: ---------\")\n",
    "    evaluate_score(test_recharge_label,predict_prob_recharge)\n",
    "\n",
    "print('-'*40+\" plot and evaluate end \"+'-'*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aeb2f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 11:09:40.841721: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/4.2.3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fbea488da90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fc15fe49a30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "print(len(trained_models))\n",
    "trained_models[0].save(\"../model/4.2.3.online/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8a1b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_online = keras.models.load_model('../model/4.2.3.online/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94600250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 18s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_result_online=model_online.predict(x={'cate_inputs_0': test_cate_fea[:,0],\n",
    "                                    'cate_inputs_1': test_cate_fea[:,1],\n",
    "                                    'cate_inputs_2': test_cate_fea[:,2],\n",
    "                                    'text_inputs': test_text_fea,\n",
    "                                    'numeric_inputs':test_numeric_fea}\n",
    "                                 ,verbose=1,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0fd0a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------消耗模型评估分值: ---------\n",
      "accuracy: 0.743\n",
      "ovr macro auc: 0.784\n",
      "ovo macro auc: 0.815\n",
      "ovr weighted auc: 0.811\n",
      "ovo weighted auc: 0.824\n",
      "micro precision: 0.743\n",
      "macro precision: 0.637\n",
      "weighted precision: 0.713\n",
      "micro recall: 0.743\n",
      "macro recall: 0.552\n",
      "weighted recall: 0.743\n",
      "-----------充值模型评估分值: ---------\n",
      "accuracy: 0.938\n",
      "ovr macro auc: 0.827\n",
      "ovo macro auc: 0.873\n",
      "ovr weighted auc: 0.869\n",
      "ovo weighted auc: 0.873\n",
      "micro precision: 0.938\n",
      "macro precision: 0.464\n",
      "weighted precision: 0.957\n",
      "micro recall: 0.938\n",
      "macro recall: 0.549\n",
      "weighted recall: 0.938\n"
     ]
    }
   ],
   "source": [
    "predict_prob_cost_online=pred_result_online[0]\n",
    "predict_prob_recharge_online=pred_result_online[1]\n",
    "print(\"-----------消耗模型评估分值: ---------\")\n",
    "evaluate_score(test_cost_label,predict_prob_cost_online)\n",
    "print(\"-----------充值模型评估分值: ---------\")\n",
    "evaluate_score(test_recharge_label,predict_prob_recharge_online)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
